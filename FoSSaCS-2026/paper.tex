\documentclass[runningheads,orivec,envcountsame,envcountsect]{llncs}

\usepackage{soul} % Borrar, es solo para highlights en el draft
\usepackage[colorinlistoftodos,textsize=small]{todonotes} % Borrar, es solo para comentarios en el draft
%\setlength{\marginparwidth}{2cm}
\newcommand\Jano[1]{\todo[color=green!40]{Jano: #1}}


\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

% === Unnumbered theorem-like envs for the appendix ===
\spnewtheorem*{restatetheorem}{Theorem}{\bfseries}{}
\spnewtheorem*{restatelemma}{Lemma}{\bfseries}{}
\spnewtheorem*{restatecorollary}{Corollary}{\bfseries}{}
% ====================================================

\usepackage[b]{esvect} % variantes: [a], [b], [c], [e]...
% y usar \vv{v} en lugar de \vv{v}
\usepackage{graphicx}
\graphicspath{{figures/}}
\usepackage{amssymb}
\usepackage{amsmath}
%\usepackage{mathtools}
\allowdisplaybreaks
\usepackage{proof}
\usepackage{tikz}
\usetikzlibrary{cd,positioning,decorations.text,decorations.pathmorphing}
\tikzcdset{scale cd/.style={every label/.append style={scale=#1},cells={nodes={scale=#1}}}}
\usepackage{tikz-cd}
\usepackage[only=llparenthesis,rrparenthesis,llbracket,rrbracket]{stmaryrd}
\usepackage{qcircuit}

\usepackage{color}  % Springer pide usar este paquete de color, no xcolor   
\definecolor{darkblue}{rgb}{0,0,0.5}
\definecolor{darkgreen}{rgb}{0,0.4,0}
\usepackage[
  bookmarks,
  colorlinks=true,     
  linkcolor=darkblue,
  citecolor=darkgreen,
  urlcolor=blue,
  bookmarksopen,
  bookmarksopenlevel=2,
  bookmarksdepth=2,
  bookmarksnumbered=true
]{hyperref}

% Lo que sigue lo pide llncs obligatoriamente
\renewcommand\UrlFont{\color{blue}\rmfamily}
\urlstyle{rm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[capitalise,nameinlink]{cleveref}
\Crefname{section}{Section}{Sections}
\Crefname{figure}{Figure}{Figures}
\Crefname{table}{Table}{Tables}
\Crefname{theorem}{Theorem}{Theorems}
\Crefname{lemma}{Lemma}{Lemmas}
\Crefname{definition}{Definition}{Definitions}
\Crefname{proposition}{Proposition}{Propositions}


% \qedhere compatible con llncs (sin amsthm)
\makeatletter
\providecommand{\qed}{\hbox{\rule{1ex}{1ex}}}% por si no estuviera definido (llncs ya lo define)
\newcommand{\qedhere}{%
  \ifmmode
    \tag*{\qed}% en entornos amsmath tipo equation, align, etc.
  \else
    \hfill\qed% en texto normal
  \fi
}
\makeatother

\newtheorem{convention}{Convention}

\newcommand{\lambdaSh}{\ensuremath{\text{Lambda-}{\sharp}}}
\newcommand{\lambdaSI}{\ensuremath{\text{Lambda-}\mathcal S_1}}


\newcommand\braces[1]{\left\{#1\right\}}
\newcommand\So{\ensuremath{{\mathcal S}_1}}

\newcommand\ket[1]{\ensuremath{|#1\rangle}}
\newcommand\parts[1]{\ensuremath{{\mathcal P}_{\!\!*}({#1})}}
\newcommand\Span[1]{\ensuremath{{\mathsf{Span}}{#1}}}
\newcommand\Forg[1]{\ensuremath{{U}{#1}}}
\newcommand\Definible{\mathsf{Def}}
\newcommand\comp[2][]{#2^{\bot^{#1}}}
\newcommand\Rpart[1]{\mathsf{Re(#1)}}
\newcommand\Ipart[1]{\mathsf{Im(#1)}}

\newcommand\s[1]{\ensuremath{\mathsf{#1}}}
\newcommand\Op[1]{\ensuremath{#1^{\mathsf{op}}}}
\newcommand\SSet{\s{Set}}
\newcommand\Var{\ensuremath{\mathsf{Var}}}
\newcommand\Val{{\s V}}
\DeclareRobustCommand{\ValD}{\ensuremath{\vv{\mathsf{V}}}}
\newcommand\VecV{\s{SVec}_{\ValD}}
\newcommand\SetV{\Set_{\ValD}}

\newcommand\interp[1]{\ensuremath{\llbracket #1 \rrbracket}}
\newcommand\Hom{\s{Hom}}
\newcommand\HomS[1]{\Hom_{\SetV}(#1)}
\newcommand\HomV[1]{\Hom_{\VecV}(#1)}
\newcommand\Ob[1]{\s{Ob}(#1)}
\newcommand\lra{\longrightarrow}
\newcommand\xlra[1]{\xrightarrow{#1}}
\newcommand\Hil{\mathcal H_{\ValD}}
\newcommand\SpFun[1]{\ensuremath{{S}{#1}}}
\newcommand\Id{\mathsf{Id}}

\newcommand\lambdaQ{\ensuremath{\lambda^Q}}
\newcommand\lambdaS{\ensuremath{\lambda_{\mathcal{S1}}}}
\newcommand\lambdaH{\ensuremath{\lambda_{\sharp}}}
\newcommand\inl[1]{\ensuremath{\mathsf{inl}(#1)}}
\newcommand\inr[1]{\ensuremath{\mathsf{inr}(#1)}}
\newcommand\qlet[3]{\ensuremath{\mathsf{let }#1 = #2\ \mathsf{ in }\ #3}}
\newcommand\qmatch[5]{\ensuremath{\mathsf{match}\ #1\ \{\inl{#2}\mapsto #3\ |\ \inr{#4} \mapsto #5 \}}}
\newcommand\sspan[1]{\ensuremath{\mathsf{span}(#1)}}
\newcommand\ansubst[2]{\ensuremath{\langle #1 \rangle_{#2}}}
\newcommand\sqsubst[1]{\ensuremath{\left[ #1 \right]}}
\newcommand\AbsBasis{\ensuremath{\mathbb{A}}}
\newcommand\dom[1]{\mathrm{dom}(#1)}
\newcommand\sdom[1]{\mathrm{dom}^{\sharp}(#1)}
\newcommand\FV[1]{\mathrm{FV}(#1)}
%%% Logic
\def\limp{\Rightarrow}
\def\liff{\Leftrightarrow}
%%% Sets
\def\N{\mathbb{N}}            % set of natural numbers
\def\R{\mathbb{R}}            % set of real numbers
\def\C{\mathbb{C}}            % set of complex numbers
\def\Pow{\mathfrak{P}}        % powerset
\def\Powfin{\Pow_{\text{fin}}}  % set of finite subsets
\def\X{\mathcal{X}}           % set of variables
\def\Val{\mathrm{V}}          % set of pure values
\def\pto{\rightharpoonup}     % set of partial functions
\def\Cone{\mathrm{cone}}      % cone of a set of vectors
\def\Sph{\mathcal{S}_1}       % unit sphere
%%% Scalar product
\def\scal#1#2{\langle{#1}~|~{#2}\rangle}
\def\bigscal#1#2{\bigl\langle{#1}~\bigm|~{#2}\bigr\rangle}
\def\Bigscal#1#2{\Bigl\langle{#1}~\Bigm|~{#2}\Bigr\rangle}
\def\valscal#1#2{\left\langle{#1}~\middle|~{#2}\right\rangle}
%%% Syntax
\def\<{\langle}
\def\>{\rangle}
\def\Void{*} % void object
\def\Pair#1#2{(#1,#2)} % pairing construct
\def\Lam#1#2#3{\lambda#1^{#2}{.}#3} % lambda abstraction
%%% Let construct
\def\letkeyword{\mathsf{let}}
\def\inkeyword{\mathsf{in}}
\def\LetV#1#2{\letkeyword~\Void=#1~\inkeyword~#2}
\def\LetP#1#2#3#4#5#6{\letkeyword\,\Pair{#1^{#2}}{#3^{#4}}=#5~\inkeyword~#6}
%%% Left injection
\def\inleftkeyword{\texttt{inl}}
\def\Inl#1{\inleftkeyword(#1)}
\def\bigInl#1{\inleftkeyword\bigl(#1\bigr)}
\def\BigInl#1{\inleftkeyword\Bigl(#1\Bigr)}
%%% Right injection
\def\inrightkeyword{\texttt{inr}}
\def\Inr#1{\inrightkeyword(#1)}
\def\bigInr#1{\inrightkeyword\bigl(#1\bigr)}
\def\BigInr#1{\inrightkeyword\Bigl(#1\Bigr)}
%%% Match construct
\def\matchkeyword{\texttt{match}}
\def\Match#1#2#3#4#5{\matchkeyword~#1~%
  \{\Inl{#2}\mapsto#3~|~\Inr{#4}\mapsto#5\}}
\def\bigMatch#1#2#3#4#5{\matchkeyword~#1~%
  \bigl\{\Inl{#2}\mapsto#3~\bigm|~\Inr{#4}\mapsto#5\bigr\}}
\def\BigMatch#1#2#3#4#5{\matchkeyword~#1~%
  \Bigl\{\Inl{#2}\mapsto#3~\Bigm|~\Inr{#4}\mapsto#5\Bigr\}}
%%% Match construct for lists
\def\Nil{\ensuremath{\mathtt{nil}}}
\def\MatchL#1#2#3#4#5{\matchkeyword~#1~%
  \{\Nil\mapsto#2~|~#3::#4\mapsto#5\}}
\def\bigMatchL#1#2#3#4#5{\matchkeyword~#1~%
  \bigl\{\Nil\mapsto#2~\bigm|~#3::#4\mapsto#5\bigr\}}
\def\BigMatchL#1#2#3#4#5{\matchkeyword~#1~%
  \Bigl\{\Nil\mapsto#2~\Bigm|~#3::#4\mapsto#5\Bigr\}}
%%% If construct
\def\tt{\ensuremath{\mathtt{t\!t}}}
\def\ff{\ensuremath{\mathtt{f\!f}}}
\def\ifkeyword{\ensuremath{\mathtt{i{\mskip-1mu}f}}}
\def\If#1#2#3{\ifkeyword~#1~\{#2\mid#3\}}
\def\bigIf#1#2#3{\ifkeyword~#1~\bigl\{#2\bigm|#3\bigr\}}
\def\BigIf#1#2#3{\ifkeyword~#1~\Bigl\{#2\Bigm|#3\Bigr\}}
%%% Case construct
\def\case#1#2#3#4#5{\ensuremath{\mathsf{case}~#1~\mathsf{of}~\{#2\mapsto #4 \mid #3\mapsto #5\}}}
\def\gencase#1#2#3#4#5{\ensuremath{\mathsf{case}~#1~\mathsf{of}~\{#2\mapsto #4 \mid \dotsb \mid #3\mapsto #5\}}}
%%% Syntax (misc.)
\def\supp{\mathrm{supp}}
\def\weight{\varpi}
\def\Kron#1#2{\ensuremath{\delta_{#1,#2}}}
%%% Evaluation
\def\evalat{\mathrel{\triangleright}}
\def\nevalat{\mathrel{\not\triangleright}}
\def\lraneq{\rightsquigarrow}
\def\eval{\lra^*}
\def\lave{\mathrel{\reflectbox{$\eval$}}}
%%% Types
\def\Unit{\mathbb{U}}
\def\Bool{\mathbb{B}}
\def\arr{\rightarrow}
\def\Arr{\Rightarrow}
\def\Type{\mathbb{T}}
\def\BasisType{\Type_{\basis{}}}
%%% Semantics
\def\sem#1{\llbracket#1\rrbracket}
\def\semr#1{\{{\real}~#1\}}
\def\SUB#1#2{#1\le#2}
\def\NSUB#1#2{#1\not\le#2}
\def\EQV#1#2{#1\simeq#2}
\def\TYP#1#2#3{#1~{\vdash}~#2~{:}~#3}
\def\SORTH#1#2#3#4{#1~{\vdash}~#2\perp#3~{:}~#4}
\def\ORTH#1#2#3#4#5#6{#1~{\vdash}~(#2~{\vdash}~#3)\perp(#4~{\vdash}~#5)~{:}~#6}
\def\rnam#1{\textsc{\small\upshape(#1)}}
\def\snam#1{\textsc{\scriptsize\upshape(#1)}}
\def\real{\Vdash}
\def\ureal{\Vvdash}
%%% Misc.
\def\ds{\displaystyle}
\outer\long\def\COUIC#1{}
\def\sqrthalf{{\textstyle\frac{1}{\sqrt{2}}}}
\def\minsqrthalf{{\textstyle\bigl(-\frac{1}{\sqrt{2}}\bigr)}}
\def\isqrthalf{{\textstyle\frac{i}{\sqrt{2}}}}
\def\minisqrthalf{{\textstyle\bigl(-\frac{i}{\sqrt{2}}\bigr)}}

%%% Even more macros -- to be merged

\newcommand\pair[1]{\langle #1 \rangle}
\newcommand\Let[3]{\mathsf{let}\ {#1}={#2}\ \mathsf{in}\ {#3}}
\newcommand{\ttrue}{\ensuremath{\mathtt{t\!t}}}
\newcommand{\ffalse}{\ensuremath{\mathtt{f\!f}}}
\newcommand{\tif}[3]{\mathsf{if}\left(#1\right)\left(#2\right)\left(#3\right)}
\newcommand{\pif}[2]{\ensuremath{\mathtt{if}\left(#1\right)\left(#2\right)}}
\newcommand\trad[1]{\llparenthesis{#1}\rrparenthesis}
\newcommand\B{\mathbb B}
\newcommand\XB{\mathbb X}
\newcommand\Hd{\mathbb{H}}
\newcommand\Q{\sharp\B}
\newcommand{\True}{\mathbb{T}}
\newcommand{\False}{\mathbb{F}}
\newcommand{\Cx}{\mathbb{C}}
\newcommand{\cnot}[2]{\mathsf{CNOT}\ #1\ #2}
\newcommand{\pauliX}[1]{\mathsf{NOT}\ #1}
\newcommand{\pauliZXB}{\mathsf{Z}_{\XB}}
\newcommand{\cnotXB}[2]{\mathsf{CNOT}_{\XB}\ #1\ #2}
\newcommand{\pauliXXB}[1]{\mathsf{NOT}_{\XB}\ #1}
\newcommand{\Bell}{\mathsf{Bell}}
\newcommand{\lambdaB}{\lambda_B}
%%% If construct
\newcommand\basis[1]{\ensuremath{\mathsf{B}_{#1}}}
\newcommand\genbasis[3]{\ensuremath{B_{\{#1\}_{#2}^{#3}}}}

%%% Teleportation algorithm

\newcommand{\bellcase}[5]{\ensuremath{\mathsf{case}~#1~\mathsf{of}~ 
\{\Phi^+ \mapsto \Pair{\Phi^+}{#2} \mid
\Phi^- \mapsto \Pair{\Phi^-}{#3} \mid
\Psi^+ \mapsto \Pair{\Psi^+}{#4} \mid
\Psi^- \mapsto \Pair{\Psi^-}{#5} \}}}

\begin{document}

\title{Basis-Sensitive Quantum Typing via Realizability}

%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
\author{Anonymous Author(s) for submission}

%\author{
%  Alejandro DÃ­az-Caro\inst{1,2} %\orcidID{0000-0002-5175-6882}
%  \and
%  Octavio Malherbe\inst{3} %\orcidID{0009-0004-0624-9285}
%  \and
%  Rafael Romero\inst{2,4} %\orcidID{?}
%}
%
%\authorrunning{A. DÃ­az-Caro, O. Malherbe, and R. Romero}
%
%\institute{
%  UniversitÃ© de Lorraine, CNRS, Inria, LORIA, France
%  %\\\email{alejandro.diaz-caro@inria.fr}
%  \and
%  Universidad Nacional de Quilmes, Argentina
%  \and
%  Universidad de la RepÃºblica, Facultad de IngenierÃ­a, IMERL, Uruguay
%  %\email{malherbe@fing.edu.uy}
%  \and
%  ICC, CONICET-Universidad de Buenos Aires, Argentina\\
%  %\email{lromero@dc.uba.ar}
%}

\maketitle 

\begin{abstract}
  The abstract should briefly summarize the contents of the paper in 150--250 words.

  \keywords{First keyword  \and Second keyword \and Another keyword.}
\end{abstract}



\section{Introduction}
The no-cloning theorem \cite{WoottersZurek1982} and the no-deleting theorem
\cite{PatiBraunstein2000} are two well-known results in quantum mechanics that
state it is impossible to copy or delete an arbitrary qubit. This stands in
stark contrast with classical information, where copying and deleting data are
routine operations. There is, however, a subtlety: although arbitrary qubits
cannot be copied or deleted, this is possible for known---and, in the case of
deletion, separable---qubits. This implies that qubits with known values behave
as classical data and can be treated accordingly. Moreover, it suffices to know
the basis to which a qubit belongs in order to copy and, to some extent, delete it.

In most quantum programming languages, qubits are defined with respect to a
canonical basisâoften referred to as the computational basis. In this setting,
classical bits correspond to the basis vectors, whereas qubits are unit-norm
linear combinations of them. Classical bits can be copied and deleted freely,
while such operations on arbitrary qubits are restricted.

In this paper we introduce a quantum $\lambda$-calculus within the
quantum-control paradigmâby contrast with the classical-control one, where the
control flow is classical and cannot be superposed. Our approach is inspired by
a line of work on basis-sensitive quantum typing. The earliest system,
Lambda-S \cite{DiazcaroDowekRinaldiBIO19}, could distinguish whether a qubit
was in the computational basis, allowing duplication and erasure only in that
case. Later, Lambda-S$_1$
\cite{DiazcaroGuillermoMiquelValironLICS19,DiazCaroMalherbe2022} refined this
approach by restricting to unit-norm vectors, introducing higher-order
abstractions, and ensuring that terms of type qubit-to-qubit denote unitary
maps. More recently, the Lambda-SX calculus \cite{DiazcaroMonzonAPLAS25}
generalised Lambda-S to arbitrary non-entangled single-qubit bases, albeit
through a purely syntactic framework restricted to first order. The calculus we
present here extends these ideas to a unit-norm, higher-order setting over
multiple-qubit bases, grounded in a realizability semantics.

The realizability methodology, originating with Kleene's work on Heyting
arithmetic \cite{KleeneJSL45}, provides a constructive framework that connects
operational semantics with type systems. In our context, it allows the
extraction of a sound type system directly from the reduction semantics of the
calculus, ensuring that safety properties hold by construction. The approach
proceeds as follows:
\begin{enumerate}
  \item Define a calculus with a deterministic evaluation strategy.
  \item Define types as sets of closed values in the language.
  \item Define the typing judgement so that asserting that a term has a given
  type is, by definition, to state that the term reduces to a value of the
  corresponding type.
\end{enumerate}
Each typing rule therefore corresponds to a provable theorem in this setting.
Rather than building ad hoc typing rules, the system is derived from the
computational content of the calculus, making it possible to define whole
families of type systems by proving the validity of new rules.

Following this approach, we enrich abstractions with explicit basis
decorations. Intuitively, the reduction system treats values expressed in the
chosen basis as classical data, while linear combinations of these values
represent quantum data and reduce linearly within the term. This refinement
enables duplication and erasure for qubits in known bases while maintaining
linear handling for unknown qubits.

The objective of this work is twofold. First, to employ the extracted type
system to provide a more precise description of programs. Second, to take
advantage of the extended syntax to express quantum algorithms in a flexible
and compositional way, rather than merely translating circuits.

The idea of tracking non-computational bases has been explored before, notably
in \cite{Perdrix2008,DiazcaroMonzonAPLAS25}. In \cite{Perdrix2008}, Perdrix
introduces an abstract model that tracks the basis of qubits to perform static
entanglement analysis. In \cite{DiazcaroMonzonAPLAS25}, Monzon and DÃ­az-Caro
present a $\lambda$-calculus integrating basis information into the type system,
proving meta-theoretic and safety results that make it a solid proof of concept
for basis-aware typing. We build upon these ideas, extending them beyond
single-qubit bases to encompass multi-qubit entangled bases, and recovering
higher-order computation to approach the expressive power of modern functional
languages.

\paragraph{Contributions.}
The contributions of this paper can be summarised as follows.
\begin{itemize}
  \item We introduce a \emph{basis-sensitive} quantum $\lambda$-calculus in the
  quantum-control paradigm, extending previous systems to a setting that is
  unit-norm, higher-order, and supports multiple-qubit entangled bases.
  \item We provide a \emph{realizability-based semantics} that connects the
  operational reduction system with the extracted type system, ensuring safety
  by construction.
  \item We formalise a \emph{type algebra} capable of tracking basis
  information throughout programs, and derive typing rules corresponding to
  provable theorems in the realizability interpretation.
  \item We illustrate the expressive power of the calculus through examples
  involving basis-dependent operations and multi-qubit structures, showing how
  it subsumes and extends previous single-basis approaches.
\end{itemize}

The structure of the paper is as follows.  In
\Cref{sec:calculus}, we introduce the core
language, its syntax, congruence rules, and basis-dependent substitution.
\Cref{sec:reduction} details the
operational semantics.  \Cref{sec:model}
presents the realizability model, including
unitary type semantics, the characterisation of unitary operators, and the
typing rules.  \Cref{sec:examples} illustrates the
calculus through representative programs.  All omitted proofs are deferred to
the appendices.  Finally, we conclude with remarks and directions for future
work in \Cref{sec:conclusion}.

\section{Core language}\label{sec:calculus}
\subsection{Syntax and congruence}
This section presents the calculus on which our realizability model will be
built. It is a $\lambda$-calculus extended with linear combinations of terms,
forming a vector space. 

The syntax of the calculus is described in
\Cref{tab:Syntax}. The calculus is divided into four
distinct syntactic categories: \emph{pure values} ($\Val$), \emph{pure terms}
($\Lambda$), \emph{value distributions} ($\ValD$), and \emph{term
distributions} ($\vec\Lambda$). Values are composed of variables, decorated
lambda abstractions, and two basis values representing orthogonal vectors,
$\ket 0$ and $\ket 1$. A pair of values is also considered a value.  Terms
include values, applications, pair constructors and destructors, and pattern
matching for orthogonal vectors, represented by the $\mathsf{case}$ operator.
Both term and value distributions are built as $\C$-linear combinations of
terms and values, respectively. In \Cref{tab:PairsNotation}
we also include notation for linear combinations of
pairs. We stress that this notation for pairs does not appear in the syntax,
but is rather useful to describe specific states.

We use $v,u,w$ to denote values and $t,s,r$ for terms, writing $\vv{\cdot}$ when
they are distributions.

\begin{table}[t]
  \begin{align*}
    v &::= x \mid \Lam{x}B{\vv{t}} \mid (v, v) \mid \ket{0} \mid \ket{1} &
    (\Val)\\
    t &::= w \mid tt \mid (t,t) \mid
    \LetP{x}{B_1}{y}{B_2}{\vv{t}}{\vv{t}}\mid
    \gencase{\vv{t}}{\vv{v}}{\vv{v}}{\vv{t}}{\vv{t}} &
    (\Lambda) \\
    \vv{v} &::= v \mid \vv{v}+\vv{v} \mid \alpha \vv{v} \mid \vv 0
    \qquad\hfill(\alpha\in\C) & (\ValD) \\
    \vv{t} &::= t \mid \vv{t}+\vv{t} \mid \alpha \vv{t} \mid \vv 0
    \qquad\hfill(\alpha\in\C) & (\vv \Lambda)
  \end{align*}
  \caption{Syntax of the calculus, where $B, B_1, B_2$ are sets of value
  distributions ($B, B_1, B_2 \subseteq \ValD$).}
  \label{tab:Syntax}
\end{table}

\begin{table}[t]
  \[
    \Pair{\alpha  v+\vv{v_1}}{\vv{v_2}} 
    := \alpha\Pair{v}{\vv{v_2}} + \Pair{\vv{v_1}}{\vv{v_2}}
    \qquad\qquad
    \Pair{w}{\alpha  v+\vv{v_1}} 
    := \alpha\Pair{w}{v} + \Pair{w}{\vv{v_1}}
  \]
  \caption{Notation for pair distributions}
  \label{tab:PairsNotation}
\end{table}

The subsets $B$, $B_1$, and $B_2$ appearing in the abstractions and pair
destructors denote the bases of the vector spaces in which the terms are
expressed; their precise nature is made explicit below.
Before formally defining the notion of bases, we first establish the
algebraic structure underlying the space of value distributions.
This is achieved by introducing the congruence relation defined in
\Cref{tab:Congruence}.
The congruence captures the intended behaviour of addition and scalar
multiplication, allowing us to treat linear combinations of terms and values
as genuine algebraic entities rather than mere syntactic constructions.
In particular, it enforces the commutativity and associativity of addition and
the distributivity of scalar multiplication, thereby justifying summation
notation~$\sum$.

\begin{table}[t]
  \begin{align*}
    0\vec t &\equiv \vv 0 & \vec t+\vv 0 &\equiv \vec t \\
    1\vv{t} &\equiv \vv{t} &
    \alpha(\beta\vv{t}) &\equiv (\alpha\beta)\vv{t} \\
    \vv{t_1}+\vv{t_2} &\equiv \vv{t_2}+\vv{t_1} &
    (\vv{t_1}+\vv{t_2})+\vv{t_3} &\equiv \vv{t_1}+(\vv{t_2}+\vv{t_3}) \\
    (\alpha+\beta)\vv{t} &\equiv \alpha\vv{t}+\beta\vv{t} &
    \alpha(\vv{t_1}+\vv{t_2}) &\equiv \alpha\vv{t_1}+\alpha\vv{t_2} \\
    \vv{t}(\alpha\vv{s}) &\equiv \alpha(\vv{t}\vv{s}) &
    (\alpha\vv{t})\vv{s} &\equiv \alpha(\vv{t}\vv{s}) \\
    (\vv{t}+\vv{s})\vv{r} &\equiv \vv{t}\vv{r}+\vv{s}\vv{r} &
    \vv{t}(\vv{s}+\vv{r}) &\equiv \vv{t}\vv{s}+\vv{t}\vv{r} &&
  \end{align*}
  \begin{align*}
    \LetP{x_1}{A_1}{x_2}{B_2}{(\alpha\vv{t})}{\vv{s}}
    &\equiv \alpha(\LetP{x_1}{A_1}{x_2}{B_2}{\vv{t}}{\vv{s}}) \\
    \LetP{x_1}{A_1}{x_2}{B_2}{\vv{t}+\vv{s}}{\vv{r}}
    &
    \equiv
    \begin{aligned}[t]
      &(\LetP{x_1}{A_1}{x_2}{B_2}{\vv{t}}{\vv{r}})\\
      &+(\LetP{x_1}{A_1}{x_2}{B_2}{\vv{s}}{\vv{r}}) 
    \end{aligned}\\
    \gencase{\alpha \vv{t}}{\vv{v_1}}{\vv{v_n}}{\vv{s_1}}{\vv{s_n}}
    &\equiv \alpha(\gencase{\vv{t}}{\vv{v_1}}{\vv{v_n}}{\vv{s_1}}{\vv{s_n}}) \\
    \gencase{(\vv{t}+\vv{s})}{\vv{v}}{\vv{w}}{\vv{r_1}}{\vv{r_2}}
    &\equiv\begin{aligned}[t]
      &\gencase{\vv{t}}{\vv{v}}{\vv{w}}{\vv{r_1}}{\vv{r_2}}\\
      &+\gencase{\vv{s}}{\vv{v}}{\vv{w}}{\vv{r_1}}{\vv{r_2}}
    \end{aligned}
  \end{align*}
  \caption{Term congruence}
  \label{tab:Congruence}
\end{table}

The rules in \Cref{tab:Congruence} ensure that the
set of value distributions satisfies the axioms of a vector space.  The notion
of basis in this calculus builds on this algebraic foundation. Once the vector
structure is established, we can define which subsets $B\subseteq \ValD$
qualify as \emph{bases}, thereby justifying the decorations appearing in the
syntax of \Cref{tab:Syntax}.


Before proceeding further, let us briefly illustrate the intuition behind
the congruence of \Cref{tab:Congruence}.
The key idea of the calculus is that arguments are decomposed over the bases
associated with their corresponding abstractions.
As in linear algebra, a vector can be rewritten as a linear combination of
basis elements; for instance,
\[
  (1,0)
  = \tfrac{1}{\sqrt{2}}\!\left(\tfrac{(1,1)}{\sqrt{2}}
  + \tfrac{(1,-1)}{\sqrt{2}}\right)
\]
expresses $(1,0)$ in the basis
$\{\tfrac{(1,1)}{\sqrt{2}}, \tfrac{(1,-1)}{\sqrt{2}}\}$.
By identifying $(1,0)$ with $\ket{0}$ and $(0,1)$ with $\ket{1}$, we see
that the calculus allows every vector (or value distribution)
to be expressed as a superposition of elements of the basis attached to
each abstraction.
The congruence ensures that these linear combinations behave
algebraically as in a complex vector space, supporting the standard
rules of addition, scalar multiplication, and the zero vector.



The core mechanism of the calculus lies in decorating variable bindings with
sets of value distributions. Following linear algebra terminology, we refer to
these sets as \emph{(orthonormal) bases}, as we will define later. These bases
inform the reduction system on how to operate on their arguments.

To properly characterise the sets that decorate the lambda abstractions, we
must first specify the kind of values they contain.
\begin{definition}[Qubits]\label{def:Qubit}
  A \emph{one-dimensional qubit} is a value distribution of the form
  $\alpha\ket{0} + \beta\ket{1}$, where $|\alpha|^2 + |\beta|^2 = 1$. An
  \emph{$n$-dimensional qubit} is a value distribution of the form
  $\alpha\Pair{\ket{0}}{\vv{w_1}} + \beta\Pair{\ket{1}}{\vv{w_2}}$, where
  $\vv{w_1}$ and $\vv{w_2}$ are $(n-1)$-dimensional qubits, and $\alpha$ and
  $\beta$ satisfy the same normalisation condition.
\end{definition}
We may use the usual Dirac shorthand $\ket{xy}$ for $(\ket{x},\ket{y})$, and
similarly for longer tuples.

From now on, we call the value distributions, i.e. the elements of $\ValD$,
\emph{vectors}. The vector space $\ValD$ is equipped with an inner
product $\scal{\vv v}{\vv w}$ and an $\ell_2$-norm $\|\vv v\|$ defined as:
\[
  \scal{\vv{v}}{\vv{w}} := \sum_{i=1}^n\sum_{j=1}^m
  \overline{\alpha_i}\,\beta_j\,\delta_{v_i,w_j},
  \qquad\qquad
  \|\vv{v}\| := \sqrt{\scal{\vv{v}}{\vv{v}}}
  = \sqrt{\sum_{i=1}^n|\alpha_i|^2},
\]
where $\vv{v}=\sum_{i=1}^n\alpha_i v_i$ and
$\vv{w}=\sum_{j=1}^m\beta_j w_j$, and $\delta_{v_i,w_j}$ is the Kronecker
delta, equal to $1$ if $v_i=w_j$ and $0$ otherwise.

With this notion of inner product, we can complete the description of the
calculus syntax. As expected, two values are \emph{orthogonal} when their inner
product is equal to zero. Using this, we can now formally define the sets that
decorate abstractions.
\begin{definition}[Basis]\label{def:NthDimensionalBasis}
  A set of value distributions $B$ is an \emph{$n$-dimensional orthonormal
  basis} if it satisfies:
  \begin{enumerate}
    \item Each element of $B$ is an $n$-dimensional qubit \emph{(cf.~\Cref{def:Qubit})}.
    \item Each element has norm $1$.
    \item Distinct elements of $B$ are pairwise orthogonal.
  \end{enumerate}
\end{definition}

From now on, the syntax introduced in \Cref{tab:Syntax}
is restricted to sets $B$ forming $n$-dimensional
orthonormal bases.


Unlike the standard definition of an orthonormal basis, we also require that
its elements be qubitsâneither variables nor abstractions. Intuitively, these
sets record the basis in which a term is expressed. A qubit belonging to such a
set is treated under a call-by-value strategy, allowing its data to be handled
classically. Any other qubit is first decomposed as a $\C$-linear combination
of the basis elements, after which the function is applied linearly to each
component. If an argument cannot be expressed in the decorating basis, the
evaluation becomes stuck.

As in classical linear algebra, no non-trivial linear combination of basis
elements yields the null vector; otherwise, some basis vector would violate
pairwise orthogonality. Consequently, each decomposition over a basis is
unique.

\begin{theorem}[Unique decomposition]\label{thm:UniqueDecomposition}
  If $B$ is an $n$-dimensional basis, then every $n$-dimensional qubit has a
  unique decomposition over $B$.
  \qed
\end{theorem}

\begin{corollary}[Preservation under congruence]\label{cor:EquivalentDecomposition}
  If $\vv{v} \equiv \vv{w}$, then they share the same decomposition over any
  basis $B$.
  \qed
\end{corollary}

From now on, we let $\B=\{\ket{0},\ket{1}\}$ denote the classical computational
basis. Similarly, we define
$\ket{+}:=\frac 1{\sqrt{2}}(\ket{0}+\ket{1})$ and
$\ket{-}:=\frac 1{\sqrt{2}}(\ket{0}-\ket{1})$, and let
$\XB=\{\ket{+},\ket{-}\}$.

\subsection{Basis-dependent substitutions}
Beta-reduction depends on the basis chosen for the abstraction, so we must
define a substitution that takes this mechanism into account. Intuitively, this
operation substitutes variables with vectors expressed in the chosen basis; the
accompanying coefficients are those of the value distribution being
substituted.

Alongside this substitution, we introduce a special basis, denoted
$\AbsBasis$, which acts as the canonical basis for $\lambda$-abstractions. In
this way, we restrict function distributions to a single admissible basis.

Before introducing the basis-dependent substitution, let us recall the
standard notation. For a term distribution $\vv t$, a variable $x$, and a
value distribution $\vv v$, the expression $\vv t[\vv v/x]$ denotes the
usual capture-avoiding substitution of $\vv v$ for $x$ in $\vv t$.

\begin{definition}[Basis-dependent substitution]
  Let $\vv t$ be a term distribution, $\vv v$ a value distribution, $x$ a
  variable, and $B$ an orthonormal basis. We define the substitution
  $\vv t\ansubst{\vv v/x}{B}$ as follows:
  \[
    \vv t\ansubst{\vv v/x}{B} \;=\;
    \begin{cases}
      \ds\sum_{i\in I}\alpha_i\,\vv t\,[\vv{b_i}/x] &
        \text{if } B=\{\vv{b_i}\}_{i\in I}\ \text{and}\
        \vv v \equiv \ds\sum_{i\in I}\alpha_i\,\vv{b_i},\\[6pt]
      \ds\sum_{i\in I}\alpha_i\,\vv t\,[v_i/x] &
        \text{if } B=\AbsBasis\ \text{and}\
        \vv v = \ds\sum_{i\in I}\alpha_i\,v_i,\\[2pt]
      \text{undefined} & \text{otherwise.}
    \end{cases}
  \]
  The definition also extends to pairs of values. If
  $\vv v=\sum_{i\in I}\alpha_i\,\Pair{\vv{v_i}}{\vv{w_i}}$, then
  \[
    \vv t\ansubst{\vv v/x\otimes y}{B_1\otimes B_2}
      \;=\; \sum_{i\in I}\alpha_i\,
      \bigl(\vv t\ansubst{\vv{v_i}/x}{B_1}\ansubst{\vv{w_i}/y}{B_2}\bigr),
  \]
  where $B_1$ and $B_2$ are (orthonormal) bases---or $\AbsBasis$---associated
  with $x$ and $y$, respectively; the symbol $\otimes$ in $B_1\otimes B_2$ is
  purely notational.
\end{definition}

\paragraph{Remark.}
The two cases in the definition capture distinct substitution modes.  
In the first, substitution proceeds linearly using the decomposition of
$\vv v$ over the explicit basis $B$.  
In the second, when $B=\AbsBasis$, substitution proceeds linearly over the pure
values that form $\vv v$.  
This case recovers the substitution mechanism of earlier
basis-sensitive calculi---such as the one in
\cite{DiazcaroGuillermoMiquelValironLICS19}---but generalises it by introducing
basis-dependent behaviour.  
This special case is also the only one applicable to
$\lambda$-abstractions, since abstractions cannot belong to orthonormal bases.


\begin{example}
  Let
  \(
    \vv v
    = \tfrac{1}{\sqrt{2}}\Pair{\ket{0}}{\ket{1}}
      - \tfrac{1}{\sqrt{2}}\Pair{\ket{1}}{\ket{0}}
    \),
  which, using the notation introduced after \Cref{def:Qubit}, can also be written as
  $\vv v = \tfrac{1}{\sqrt{2}}\ket{01}
           - \tfrac{1}{\sqrt{2}}\ket{10}$.
  Then the substitution
  $(y,x)\ansubst{\vv v/x\otimes y}{\B\otimes\B}$ yields
  \begin{align*}
    (y,x)\ansubst{\vv v/x\otimes y}{\B\otimes\B}
    &= \tfrac{1}{\sqrt{2}}\,(y,x)[\ket{0}/x][\ket{1}/y]
       - \tfrac{1}{\sqrt{2}}\,(y,x)[\ket{1}/x][\ket{0}/y] \\
    &= \tfrac{1}{\sqrt{2}}\,(\ket{1},\ket{0})
       - \tfrac{1}{\sqrt{2}}\,(\ket{0},\ket{1}),
  \end{align*}
  that is,
  $\tfrac{1}{\sqrt{2}}\ket{10}
   - \tfrac{1}{\sqrt{2}}\ket{01}$.
  Thus, as expected, the substitution on $(y,x)$ effectively swaps the two
  components of the pair.
\end{example}

With this new substitution in place, we can establish a few properties that
will later be instrumental in proving the soundness of typing judgements.

We first show that basis-dependent substitution distributes over linear
combinations of terms.

\begin{lemma}[Distributivity over linear combinations]\label{lem:distributiveSubstitution}
  For term distributions $\vv{t_i}$, a value distribution $\vv{v}$, a
  variable $x$, coefficients $\alpha_i\in\C$, and a basis $B$ such that
  $\ansubst{\vv v/x}{B}$ is defined:
  \[
    \Bigl(\sum_i \alpha_i\vv{t_i}\Bigr)\ansubst{\vv v/x}{B}
    \equiv
    \sum_i \alpha_i\vv{t_i} \ansubst{\vv v/x}{B}.
    \tag*{\qed}
  \]
\end{lemma}

The next result states that substitution behaves consistently within each
equivalence class induced by the congruence $\equiv$.

\begin{lemma}[Compatibility with congruence]\label{lem:EquivSubstitutions}
  For value distributions $\vv{v},\vv{w}$, a term distribution $\vv{t}$, and
  an orthonormal basis $B$ such that both
  $\ansubst{\vv{v}/x}{B}$ and $\ansubst{\vv{w}/x}{B}$ are defined:
  if $\vv{v}\equiv\vv{w}$, then
  $\vv{t}\ansubst{\vv{v}/x}{B}
  =\vv{t}\ansubst{\vv{w}/x}{B}$.
  \qed
\end{lemma}

\begin{remark}[Non-invariance across bases]
  The property in \Cref{lem:EquivSubstitutions} does not extend across
  different bases; that is,
  $\vv{t}\ansubst{\vv{v}/x}{A}\not\equiv\vv{t}\ansubst{\vv{v}/x}{B}$.
  For example,
  \[
    (\Lam{x}{C}{y})\ansubst{\ket{+}/y}{\XB}
    = \Lam{x}{C}{\ket{+}} 
    \not\equiv
    \tfrac{1}{\sqrt{2}}\big((\Lam{x}{C}{\ket{0}})
    + (\Lam{x}{C}{\ket{1}})\big)
    = (\Lam{x}{C}{y})\ansubst{\ket{+}/y}{\B}.
  \]
  This difference arises because the relation $\equiv$ does not commute with
  lambda abstraction, nor with the case construct. Although the two terms are
  operationally equivalent, the calculus distinguishes between the
  superposition of results,
  $\Lam{x}{B}{\alpha\vv{v_1} + \beta\vv{v_2}}$,
  and the superposition of functions,
  $\alpha(\Lam{x}{B}{\vv{v_1}}) + \beta(\Lam{x}{B}{\vv{v_2}})$.
  This distinction reflects a physical intuition: the former corresponds to a
  single experiment producing a superposition of outcomes, while the latter
  represents a superposition of distinct experiments.
\end{remark}

Finally, we introduce a convenient notation for generalised substitutions over
a term by closed values. A substitution $\sigma$ can be seen as a finite set of
individual substitutions applied consecutively to a term. Formally, for a term
$\vv{t}$, closed value distributions $\vv{v_1},\dots,\vv{v_n}$, variables
$x_1,\dots,x_n$, and bases $B_1,\dots,B_n$:
\[
  \vv{t}\ansubst{\sigma}{}
  := \vv{t}\ansubst{\vv{v_1}/x_1}{B_1}\dotsb\ansubst{\vv{v_n}/x_n}{B_n}.
\]
Since each $\vv{v_i}$ is closed, the order of substitutions is irrelevant. We
regard $\sigma$ as a partial function from variables to pairs of closed value
distributions and bases, and write $\dom{\sigma}$ for its domain. The operation
extends naturally: for a term $\vv{t}$, substitution $\sigma$, a new variable
$x\notin\dom{\sigma}$, value distribution $\vv{v}$, and basis $B$,
\[
  \vv{t}\ansubst{\sigma}{}\ansubst{\vv{v}/x}{B}
  = \vv{t}\ansubst{\sigma'}{},
\]
where $\sigma'$ extends $\sigma$ by mapping $x$ to $(\vv v,B)$. Likewise, two
disjoint substitutions $\sigma_1$ and $\sigma_2$ can be merged:
\[
  \vv{t}\ansubst{\sigma_1}{}\ansubst{\sigma_2}{}
  = \vv{t}\ansubst{\sigma'}{},
\]
where $\dom{\sigma_1}\cap\dom{\sigma_2}=\emptyset$ and $\sigma'$ coincides with
$\sigma_i$ on $\dom{\sigma_i}$ for $i=1,2$.


\section{Operational semantics}\label{sec:reduction}

The reduction system implements a mechanism in which every vector in the space
is interpreted with respect to the basis attached to each abstraction. An
evaluation step is permitted only when the argument can be decomposed onto that
basis. The reduction rules, presented in
\Cref{tab:Reduction}, define the elementary
reduction relation~$\lraneq$. Terms are considered modulo the congruence
introduced in \Cref{tab:Congruence}, so the
effective reduction used throughout the paper is the one
\emph{modulo~$\equiv$}, written~$\lra$.  Formally, a step $\vv t\lra\vv r$
abbreviates a reduction $\vv t'\lraneq\vv r'$ such that $\vv t\equiv\vv t'$
and $\vv r'\equiv\vv r$.

\begin{table}[t]
  \begin{align*}
    \text{If }\vv{t}\ansubst{\vv v/x}{A}\text{ is defined,}\quad
    (\Lam{x}{A}{\vv{t}})\vv{v}
    &\lraneq \vv{t}\ansubst{\vv v/x}{A}\\
    \text{If }\vv{t}\ansubst{\vv v/x}{B_1\otimes B_2}\text{ is defined,}\quad
    \LetP{x}{B_1}{y}{B_2}{\vv v}{\vv{t}}
    &\lraneq \vv{t}\ansubst{\vv{v}/x\otimes y}{B_1\otimes B_2}\\
    \gencase{\sum_{i=1}^{n}\alpha_i \vv{v_i}}{\vv{v_1}}{\vv{v_n}}{\vv{t_1}}{\vv{t_n}}
    &\lraneq \sum_{i=1}^{n}\alpha_i \vv{t_i}
  \end{align*}
  \[
    \begin{array}{c}
      \infer{st\lraneq s\vv r}{t\lraneq \vv r}
      \qquad\qquad
      \infer{tv\lraneq \vv rv}{t\lraneq\vv r}
      \qquad\qquad
      \infer{\alpha t\lraneq \alpha \vec r}{t\lraneq\vec r & \alpha\neq 0}
      \qquad\qquad
      \infer{t+\vv s\lraneq\vv r+\vv s}{t\lraneq\vv r}
      \\[5pt]
      \infer{\LetP{x}{A}{y}{B}{t}{\vv{s}}\lraneq
      \LetP{x}{A}{y}{B}{\vv r}{\vv{s}}}{t\lraneq \vv r} 
      \\[5pt]
      \infer{\gencase{\vv t}{\vv v}{\vv w}{\vv{s_1}}{\vv{s_n}}\lraneq
      \gencase{\vv r}{\vv v}{\vv w}{\vv{s_1}}{\vv{s_n}}}{t\lraneq \vv r}
    \end{array}
  \]
  \caption{Reduction system}
  \label{tab:Reduction}
\end{table}

The side condition~$\alpha\neq0$ in the contextual rule for scalar
multiplication prevents vacuous reductions such as $0t\lraneq 0r$, which would
otherwise introduce spurious nondeterminism. This ensures that the reduction
relation~$\lraneq$ remains deterministic.

The three main rules are the $\beta$-reduction, the $\mathsf{let}$ binding, and
the $\mathsf{case}$ pattern matching. Both the $\lambda$ abstraction and the
$\mathsf{let}$ binding attach an orthonormal basis to the variables they bind.
These bases keep track of which vectors are considered classical data.  Any
$\C$-linear combination of such vectors is treated as quantum data; that is, it
reduces linearly using the congruence rules in
\Cref{tab:Congruence}, thus making $t(\alpha\vec
s+\beta\vv r)$ equivalent to $\alpha\,t\vv s+\beta\,t\vv r$.

The only exception arises in higher-order reductions. Since no orthogonal bases
are defined for abstractions, we introduce a special basis~$\AbsBasis$, which
acts as the canonical basis for higher-order values. It can be regarded as consisting
of all pure values. For example:
\[
  (\Lam{x}{\AbsBasis}{\vv{t}})
  \sum_{i=1}^{n}\alpha_i(\Lam{y}{\basis{X}}{\vv{s_i}})
  \lra
  \sum_{i=1}^n\alpha_i\vv t[\Lam{y}{\basis{X}}{\vv{s_i}}/x].
\]

The $\mathsf{case}$ pattern matching controls program flow. It generalises the
$\mathsf{if}$--$\mathsf{then}$--$\mathsf{else}$ branching, but we do not fix
the booleans $\mathsf{true}$ and $\mathsf{false}$. Instead, each operator keeps
track of a set of orthogonal values and tests whether the argument equals each
vector, selecting the matching branch. If the argument is a linear combination
of several vectors, the result is the corresponding linear combination of the
branches. For example:
\[
  \case{\ket{-}}{\ket{0}}{\ket{1}}{\vv{t_1}}{\vv{t_2}} \lra
  \tfrac{1}{\sqrt{2}}\,\vv{t_1} - \tfrac{1}{\sqrt{2}}\,\vv{t_2}.
\]

The advantage over a binary conditional is the ability to match against several
vectors simultaneously. For boolean tuples this makes no difference, as each
component can be treated independently. However, there are orthogonal bases
that cannot be expressed as the product of smaller bases. In such cases, the
general $\mathsf{case}$ allows us to match directly against those vectors. For
example, using the \emph{Bell basis}:
\begin{align*}
  \mathsf{case}\;\vv{v}\;\mathsf{of}\;\{&
  \tfrac{1}{\sqrt{2}}(\ket{00}+\ket{11}) \mapsto \vv{t_1}\ \mid\\
  &\tfrac{1}{\sqrt{2}}(\ket{00}-\ket{11}) \mapsto \vv{t_2}\ \mid\\
  &\tfrac{1}{\sqrt{2}}(\ket{01}+\ket{10}) \mapsto \vv{t_3}\ \mid\\
  &\tfrac{1}{\sqrt{2}}(\ket{01}-\ket{10}) \mapsto \vv{t_4}\ \}
\end{align*}
This Bell basis is central in quantum communication. In
\Cref{sec:teleportation}, we revisit the quantum teleportation protocol,
which relies heavily on these states.

Defining the system in this way yields a strategy within the
\emph{call-by-value} family, namely a generalisation of the
\emph{call-by-basis} strategy introduced in~\cite{ArrighiDowekLMCS17} and
further analysed in~\cite{AssafDiazcaroPerdrixTassonValironLMCS14}. Whereas
call-by-basis fixes a single computational basis for evaluation, our variant,
which we call \emph{call-by-arbitrary-basis}, allows each abstraction to attach
its own orthonormal basis to its argument. Evaluation remains weak: no
reduction takes place under $\lambda$, pairs, $\mathsf{let}$, or
$\mathsf{case}$ constructors. This avoids unnecessary work by preventing the
reduction of subterms that might never be used.

The congruence relation on terms gives rise to different redexes. We write
$\eval$ for the reflexiveâtransitive closure of $\lra$. We can show that the
equivalence relation $\equiv$ commutes with $\eval$; in other words,
equivalence is preserved by reduction modulo~$\equiv$.

\begin{theorem}[Reduction preserves equivalence]\label{thm:confluence}
  Let $\vv{t}$ and $\vv{s}$ be closed term distributions with
  $\vv{t}\equiv\vv{s}$. If $\vv{t}\lraneq\vv{t'}$ and $\vv{s}\lraneq\vv{s'}$,
  then there exist term distributions $\vv{r_1}$ and $\vv{r_2}$ such that
  $\vv{t'}\eval\vv{r_1}$, $\vv{s'}\eval\vv{r_2}$, and
  $\vv{r_1}\equiv\vv{r_2}$.
  Diagrammatically:
  \[
    \begin{tikzcd}[row sep=small,baseline=(current bounding box.south)]
      & \vv{t}
        \arrow[ld,decorate,decoration={snake, amplitude=0.8, segment length=6pt}, ->]
        &[-3em] \equiv
        &[-3em] \vv{s}
        \arrow[rd,decorate,decoration={snake, amplitude=0.8, segment length=6pt}, ->]
        &\\
      \vv{t'}\arrow[dr,"*",pos=0.9] & & & &
      \vv{s'}\arrow[ld,"*"',pos=0.9] \\
      & \vv{r_1} & \equiv & \vv{r_2} & 
    \end{tikzcd}
    \tag*{\smash{\raisebox{.6\baselineskip}{\qed}}}
  \]
\end{theorem}

\begin{remark}\label{rmk:determinism}
  Since the reduction relation $\eval$ is defined modulo~$\equiv$, the result
  above is equivalent to stating that there exists a single distribution
  $\vv{r}$ such that $\vv{t'}\eval\vv{r}$ and $\vv{s'}\eval\vv{r}$.
  Moreover, as the elementary reduction~$\lraneq$ is deterministic, the
  reduction relation~$\lra$ is also deterministic; that is, if
  $\vv{t}\lra\vv{r_1}$ and $\vv{t}\lra\vv{r_2}$, then
  $\vv{r_1}\equiv\vv{r_2}$.
\end{remark}


\section{Realizability model}\label{sec:model}

\subsection{Unitary type semantics}
Given the deterministic machine presented in the previous section
(see~\Cref{rmk:determinism}), the next
step towards extracting a typing system is to define the sets of values that
characterise its types. To achieve this, we first need to identify the notion
of a type.

Our aim is to define types exclusively inhabited by values of norm~1. The
vectors we wish to study all belong to the \emph{unit sphere}. We write $\Sph$
for the set $\Sph := \{\vv v \in \vv{\Val} \mid \|\vv v\| = 1\}$, which
corresponds to the mathematical representation of quantum data as unit vectors
in a Hilbert space.

\begin{definition}[Unitary value distribution]
  A value distribution $\vv{v}$ is said to be \emph{unitary} if its norm equals~1,
  that is, if $\vv{v}\in\Sph$.
\end{definition}

\begin{definition}[Unitary type]
  A \emph{unitary type} (or simply a \emph{type}) is a notation~$A$ together
  with a set of unitary value distributions, denoted~$\sem{A}$, called the
  \emph{unitary semantics} of~$A$.
\end{definition}


We next move to type realizers. As our aim is to extract a quantum
lambda calculus, we wish to identify terms differing only by a global phase at
this level. Since the global phase of a quantum state has no physical
significance, we assign the same type to a term~$\vv{t}$ and to
$e^{i\theta}\vv{t}$. This idea will guide the definition of type
realizers.

\begin{definition}[Type realizer]
  Given a type~$A$ and a term distribution~$\vv t$, we say that~$\vv t$
  \emph{realizes}~$A$ (written~$\vv t \real A$) if there exists a value
  distribution~$\vv v$ such that:
  \begin{itemize}
    \item $\vv{t}\eval e^{i\theta}\vv{v}$ for some $\theta\in\R$,
    \item $\vv{v}\in\sem{A}$.
  \end{itemize}
  We denote the set of realizers of~$A$ by~$\{\real A\}$.
\end{definition}

With the notions of unitary types and their realizers in place, we can now
define a concrete approach for our language. We begin with the type grammar
given in~\Cref{tab:UnitaryTypes} and build a simple algebra from the sets of
values we aim to represent.

Before that, we introduce the notion of orthogonal complement, which will be
used in the semantics of the~$\sharp$~type:
\[
  \comp{A} = \{\, \vv{v}\in \Sph \mid \scal{\vv{v}}{a} = 0 \text{ for all } a\in A\,\}.
\]
From this point onwards, we denote by~$\Type$ the set of all types and
by~$\BasisType$ the set of all bases.

\begin{table}[t]
  \[
    A := \basis{X} \mid A\Arr A \mid A\times A \mid \sharp A,
    \qquad\text{where $X$ is any orthonormal basis.}
  \]
  \begin{align*}
    \sem{\basis{X}}&:= X\\
    \sem{A\times B}&:= \bigl\{\,(\vv v, \vv w)\;\bigm|\; \vv v\in\sem{A},~\vv w\in\sem{B}\,\bigr\}\\
    \sem{A\Arr B}&:=
    \bigl\{\,\sum_{i=1}^{n}\alpha_i(\Lam{x}{B}{\vv{t_i}})\in\Sph
      \;\bigm|\;
      \forall\vv{w}\in\sem{A},\,
      (\sum_{i=1}^{n}\alpha_i \vv{t_i})\ansubst{\vv{w}/x}{A}\real B
    \bigr\}\\
    \sem{\sharp A}&:= {(\sem{A}^\bot)}^\bot
  \end{align*}
  \caption{Type notations and semantics}
  \label{tab:UnitaryTypes}
\end{table}

The types $\basis{X}$ serve as atomic types. Each of them represents a finite
set~$X$ of orthogonal vectors forming an orthonormal basis. For instance, a
boolean type can be represented by a basis of size~2, yet we are not restricted
to a single one, since there are infinitely many bases to choose from.

Pairs are written using the same notation introduced earlier
(see~\Cref{tab:PairsNotation}).  The type~$A\times B$ corresponds to the
cartesian product of~$A$ and~$B$.  However, since the syntax admits pairs only
of pure values, the semantic clause in~\Cref{tab:UnitaryTypes} should be read
as an abbreviation for the following expanded form:
\[
  \sem{A\times B}
  := \bigl\{
       \sum_{i=1}^{n}\sum_{j=1}^{m}\alpha_i\beta_j(v_i,w_j)
       \;\bigm|\;
       \sum_{i=1}^{n}\alpha_i v_i\in\sem{A},~
       \sum_{j=1}^{m}\beta_j w_j\in\sem{B}
     \bigr\}.
\]
We stress this for rigour, but for readability we shall continue using the
concise notation of pairs.

The arrow type~$A\Arr B$ consists of distributions of $\lambda$-abstractions
that map elements of~$\sem{A}$ to realizers of~$B$.  
Finally, the type~$\sharp A$ denotes the double orthogonal complement of~$A$
intersected with the unit sphere.

The type grammar is otherwise standard, except for the constructor~$\sharp A$,
which represents quantum data---linear resources that cannot be erased or
duplicated.  

Intuitively, applying the~$\sharp$ operator to a type~$A$ yields the span of the
original interpretation (intersected with the unit sphere).  This captures the
possible linear combinations of values in the unitary semantics of~$A$, as
stated in the following proposition.

\begin{theorem}\label{thm:SharpCharacterization}
  The interpretation of a type~$\sharp A$ contains precisely the
  norm-$1$ linear combinations of values in~$\sem{A}$:
  \[
    \sem{\sharp A}
    = (\sem{A}^\bot)^\bot
    = \Span(\sem{A}) \cap \Sph.
    \tag*{\qed}
  \]
\end{theorem}



The following theorem shows that, as expected for a span, multiple
applications of the~$\sharp$ operator have no further effect beyond the first
application.

\begin{theorem}\label{thm:IdempotentSharp}
  The~$\sharp$ operator is idempotent; that is,
  $\sem{\sharp A} = \sem{\sharp(\sharp A)}$.
  \qed
\end{theorem}

\begin{remark}
  A basis type~$\basis{X}$ may consist of value distributions of pairs and can
  therefore be written as the product type of smaller bases. For example, if
  $X=\{\ket{00},\ket{01},\ket{10},\ket{11}\}$, then $\basis{X}=\B\times\B$.
  However, this is not possible for entangled bases. A clear example is the
  Bell basis:
  \[
    \mathsf{Bell}
    =\Bigl\{
      \tfrac{1}{\sqrt{2}}(\ket{00}+\ket{11}),
      \tfrac{1}{\sqrt{2}}(\ket{00}-\ket{11}),
      \tfrac{1}{\sqrt{2}}(\ket{01}+\ket{10}),
      \tfrac{1}{\sqrt{2}}(\ket{01}-\ket{10})
    \Bigr\}.
  \]
\end{remark}

It remains to verify that our type algebra indeed captures the intended sets of
value distributions. The following theorem shows that every member of a type
interpretation has norm~$1$.

\begin{theorem}\label{prop:UnitaryTypes}
  For every type~$A$, $\sem{A}\subseteq\Sph$.
  \qed
\end{theorem}

Defining types as sets of values naturally induces a semantic notion of
subtyping. We say that a type~$A$ is a subtype of a type~$B$
(written~$A\leq B$) when the set of realizers of~$A$ is included in that of~$B$,
that is, $\{\real A\}\subseteq\{\real B\}$.
If the two sets coincide, we say that $A$ and $B$ are \emph{isomorphic}
(written~$A\cong B$).

\begin{example}
  For every type~$A$, we have $A\leq\sharp A$.
  For the base types $\basis{\B}$ and $\basis{\XB}$, however,
  neither inclusion holds:
  \[
    \basis{\B}\not\leq\basis{\XB}
    \quad\text{and}\quad
    \basis{\XB}\not\leq\basis{\B}.
  \]
  Nevertheless, their linear extensions coincide,
  since $\sharp\basis{\B}\cong\sharp\basis{\XB}$.
\end{example}

Although every type is defined by norm-1 value distributions, not every
norm-1 distribution is contained in the interpretation of a type.
For example, consider the distribution
$\tfrac{1}{\sqrt{2}}(\ket{0} + \ket{00})$.
Another example is a linear combination of abstractions defined over different
bases. For instance, the term
\[
  \tfrac{1}{\sqrt{2}}(\Lam{x}{\B}{\pauliX{x}})
  + \tfrac{1}{\sqrt{2}}(\Lam{x}{\XB}{x})
\]
is not a member of an arrow type, since the bases decorating each abstraction
do not match. However, it is computationally equivalent to the abstraction
$(\Lam{x}{\B}{\ket{+}})$, which in turn belongs to the set
$\sem{\basis{\B}\Arr\basis{\XB}}$.



\subsection{Characterisation of unitary operators}


One of the main results of~\cite{DiazcaroGuillermoMiquelValironLICS19}
is the characterisation of $\C^2\to\C^2$ unitary operators using values in
$\sem{\sharp\B\Arr\sharp\B}$~\cite[Theorem IV.12]{DiazcaroGuillermoMiquelValironLICS19}.
In this subsection we extend this result. Our goal is to prove that abstractions
of type $\sharp\basis{X}\Arr\sharp\basis{Y}$, where both bases have size~$n$,
represent unitary operators
$\C^n\to\C^n$.

Unitary operators are isomorphisms between Hilbert spaces, as they preserve the
structure of the space. With this in mind, the first step is to show that the
members of $\sem{\sharp\basis{X}\Arr\sharp\basis{Y}}$ map basis vectors from
$\sem{\basis{X}}$ onto orthogonal vectors in $\sem{\sharp\basis{Y}}$. In other
words, these abstractions preserve both norm and orthogonality.

\begin{lemma}\label{lem:BasesIso}
  Let $X$ and $Y$ be orthonormal bases of the same finite
  dimension, and let $\Lam{x}{X}{\vv t}$ be a closed $\lambda$-abstraction.
  Then $\Lam{x}{X}{\vv t}\in\sem{\sharp\basis{X}\Arr\sharp\basis{Y}}$
  if and only if 
  for all $\vv{v_i},\vv{v_j}\in\sem{\basis{X}}$,
  there exist value distributions
  $\vv{w_i},\vv{w_j}\in\sem{\sharp\basis{Y}}$ such that,
  \[
    \vv{t}[\vv{v_i}/x]\eval\vv{w_i}
    \quad\text{and}\quad
    \vv{t}[\vv{v_j}/x]\eval\vv{w_j},
    \quad\text{with } 
    \vv{w_i}\perp\vv{w_j}\text{ whenever }i\neq j.
    \tag*{\qed}
  \]
\end{lemma}

Terms such as $\ket{0}$ and $\ket{1}$ are syntactic objects of the
calculus, not vectors of~$\C^2$. Nevertheless, when discussing the behaviour of
terms on Hilbert spaces, we shall occasionally abuse notation and identify
value distributions representing qubits with their corresponding canonical
basis vectors in~$\C^n$. Of course, this identification applies only to those
distributions that denote quantum data, not to general syntactic values such as
$\lambda$-abstractions---in particular, to all elements of
$\sem{\sharp\basis{X}}$ for any orthonormal basis~$X$. This identification can
be made precise as follows.

\begin{definition}
  Let $X$ be an orthonormal basis of size~$n$. For every $\vv{v}\in X$, we can
  write
  \(
    \vv{v}\equiv \sum_{i=1}^{n}\alpha_i\ket{i}
  \),
  where $\ket{i}$ denotes the $n$-qubit tuple of $\ket{0}$ and $\ket{1}$
  corresponding to the binary representation of~$i$, and
  $\sum_{i=1}^{n}|\alpha_i|^2=1$. For example, for $n=4$, $\ket{3}$ is
  $\ket{0011}$. We then define $\pi_n:X\to\C^n$ by
  \(
    \pi_n(\vv{v}) = (\alpha_1,\dotsc,\alpha_n)
  \).
\end{definition}

To lighten notation, we shall henceforth omit~$\pi_n$ and use~$\vv v$
directly.

We now establish a correspondence between $\lambda$-abstractions and operators
on~$\C^n$. Intuitively, an abstraction represents a linear operator when its
operational behaviour coincides with the action of that operator on vectors.
Formally:

\begin{definition}
  A $\lambda$-abstraction $\Lam{x}{X}{\vv{t}}$ is said to \emph{represent}
  an operator $F:\C^n\to\C^n$ if
  \[
    (\Lam{x}{X}{\vv{t}})\vv{v} \eval \vv{w}
    \quad\text{if and only if}\quad
    F(\vv{v}) = \vv{w}.
  \]
\end{definition}

In other words, a $\lambda$-term represents a function
$F:\C^n\to\C^n$ precisely when it encodes the action of~$F$ on vectors.


This definition, together with the previous lemma, allows us to build a
characterisation of unitary operators as values in
$\sem{\sharp\basis{X}\Arr\sharp\basis{X}}$.

\begin{theorem}[Characterisation of Unitary Operators]
  Let $X$ and $Y$ be orthonormal bases of size~$n$.
  A closed $\lambda$-abstraction
  $\Lam{x}{X}{\vv{t}}\in\sem{\sharp\basis{X}\Arr\sharp\basis{Y}}$
  if and only if it represents a unitary operator
  $F:\C^n\to\C^n$.
\end{theorem}

\begin{proof}
  \textit{Necessity.}
  Suppose that $\Lam{x}{X}{\vv{t}}\in\sem{\sharp\basis{X}\Arr\sharp\basis{Y}}$.
  Then, by \Cref{lem:BasesIso}, for every
  $\vv{v_i}\in\sem{\basis{X}}$ there exists
  $\vv{w_i}\in\sem{\sharp\basis{Y}}$ such that
  $\vv{t}[\vv{v_i}/x]\eval\vv{w_i}$ and
  $\vv{w_i}\perp\vv{w_j}$ whenever $i\neq j$.
  Let $F:\C^n\to\C^n$ be the operator defined by
  $F(\vv{v_i})=\vv{w_i}$.
  By linearity over~$X$, it follows that
  $\Lam{x}{X}{\vv{t}}$ represents~$F$.
  Moreover, $F$ is unitary since
  $\|\vv{w_i}\|_{\C^n}=\|\vv{w_j}\|_{\C^n}=1$ and
  $\scal{\vv{w_i}}{\vv{w_j}}_{\C^n}=0$.

  \smallskip
  \textit{Sufficiency.}
  Conversely, suppose that $\Lam{x}{X}{\vv{t}}$ represents a
  unitary operator $F:\C^n\to\C^n$.
  Then, for each $\vv{v_i}\in\sem{\basis{X}}$, there exists
  $\vv{w_i}\in\sem{\basis{Y}}$ such that
  $F(\vv{v_i}) = \vv{w_i}$ and
  $(\Lam{x}{X}{\vv{t}})\vv{v_i}\eval\vv{w_i}$.
  Hence,
  \[
    (\Lam{x}{X}{\vv{t}})\vv{v_i}
    \lraneq
    \vv{t}\ansubst{\vv{v_i}/x}{X}
    = \vv{t}[\vv{v_i}/x]
    \eval \vv{w_i}
    \in \sem{\sharp\basis{Y}},
  \]
  since $\|\vv{w_i}\|=\|F(\vv{v_i})\|_{\C^n}=1$.
  From \Cref{lem:BasesIso}, it follows that
  $\Lam{x}{X}{\vv{t}}\in\sem{\sharp\basis{X}\Arr\sharp\basis{Y}}$,
  and moreover
  \(
    \scal{\vv{w_i}}{\vv{w_j}}
    = \scal{F(\vv{v_i})}{F(\vv{v_j})}_{\C^n}
    = 0.
  \)
  \qedhere
\end{proof}

\begin{remark}
  This result naturally extends to unitary distributions of $\lambda$-abstractions, 
  since a term of the form 
  $\Lam{x}{X}{\sum_{i=1}^{n}\alpha_i \vv{t_i}}$ 
  is syntactically different but computationally equivalent to 
  $\sum_{i=1}^{n}\alpha_i \Lam{x}{X}{\vv{t_i}}$. 
  Hence, the characterisation of unitary operators also applies to 
  superpositions of abstractions sharing the same basis~$X$.
\end{remark}

\hl{Voy por acÃ¡}
\subsection{Typing rules}    
Our focus in this section is to enumerate and prove the validity of various typing rules. The objective being to extract a reasonable set of rules to constitute a type system. We first need to lay the groundwork to properly define what does it mean for a typing rule to be valid.

\begin{definition}
    A context (Denoted by capital Greek letters $\Gamma$, $\Delta$) is a mapping $\Gamma:\Var\to\Type\times\BasisType$ assigning a type and basis to each variable in its domain. We note the mapping $\Gamma(x_i)\mapsto(A_i, \basis{X_i})$ as:
    \[
    \Gamma = {x_1}_{\basis{X_1}}:A_1,\dotsb, {x_n}_{\basis{X_n}}:A_n
    \]
\end{definition}

As usual with typing judgements, the context will keep track of the type of free variables of a term. However, since the substitution operation depends on a basis we also wish to include that information. This is not strictly necessary, since the basis a variable is interpreted should not impact on the type. For example the result of the substitution:

\[
(\Lam{x}{\B}{\Pair{x}{y}})\ansubst{\ket{0}/y}{\basis{\B}} = (\Lam{x}{\B}{\Pair{x}{\ket{0}}})
\]

And the substitution:
\[
(\Lam{x}{\B}{(x, y)})\ansubst{\ket{0}/y}{\basis{\XB}} = \frac{1}{\sqrt{2}} ((\Lam{x}{\B}{\Pair{x}{\ket{+}}}) + (\Lam{x}{\B}{\Pair{x}{\ket{-}}}))
\]

Are not syntactically equivalent, but they are equivalent under elimination contexts. Therefore, since typing via realizability captures computational behaviour, the types will match. We will however keep basis information on the contexts to later simplify our proofs. With this, we can define which substitutions validate a context.

\begin{definition}
    Given a context $\Gamma$ we call the unitary semantics of $\Gamma$, noted $\sem{\Gamma}$, to the set of substitutions such that:
    \begin{align*}
      \sem{\Gamma} &:= 
      \{\sigma\text{ substitution }~\mid~ \dom{\sigma} = \dom{\Gamma}\text{ and } \forall {x_i} \in\dom{\Gamma},\\
      &\Gamma(x_i) = (A_i, \basis{X_i})\Rightarrow \sigma(x_i)=\ansubst{\vv{v_i}/x_i}{\basis{X_i}} \land \vv{v_i}\in\sem{A_i}\}
    \end{align*}
\end{definition}

In order for the calculus to be correct we need to ensure that qubits are treated linearly. The first step is to identify which variables in the context represent quantum data, those will be the ones associated with a type of the form $\sharp A$. We call the subset of $\Gamma$ composed by these variables, its \emph{strict domain}. 

\begin{definition}
    We define the strict domain of a context $\Gamma$, noted $\sdom{\Gamma}$, as:
    \[
    \sdom{\Gamma} := \{x\in\dom{\Gamma} \mid \sem{\Gamma(x)}=\sem{\sharp(\Gamma(x))}\}
    \]
\end{definition}

Here we make use of the idempotence of $\sharp$ (\Cref{thm:IdempotentSharp}) to define the strict domain. 

In order for a typing judgement $\Gamma\vdash \vv{t}: A$ to be valid, it needs to comply with two conditions. First, every free variable in the term $\vv{t}$ must be in the domain of the context $\Gamma$ and every variable in the strict context $\sdom{\Gamma}$ must appear in the term $\vv{t}$. This ensures there is no erasure of information and every variable is accounted. Linear treatment of quantum data is enforced by the substitution.

Second, every substitution in the unitary semantics of $\Gamma$, when applied to the term $\vv{t}$, must yield a term which reduces to a realizer of type $A$. This condition matches the computational behaviour of the term and context to the type. To put it more precisely: 

\begin{definition}
    We say that a typing judgement $\TYP{\Gamma}{\vv t}{A}$ is valid when:
    \begin{itemize}
        \item $\sdom{\Gamma}\subseteq\FV{\vv t}\subseteq \dom{\Gamma}$
        \item For all $\sigma\in\sem\Gamma$, $\vv{t}\ansubst{\sigma}{}\real A$
    \end{itemize}
\end{definition}

With this definition in mind, we consider a typing rule to be valid, when starting from valid judgements we reach a valid conclusion. In \Cref{tab:TypingRules} we enumerate several of these rules. One important thing to note is that there are infinite valid rules, we limit ourselves to listing a subset which could constitute a reasonable typing system for a typed calculus.

We are also interested on \emph{orthogonal terms}, that is, terms which reduce to orthogonal values. Naturally, unless these terms are closed, we need to take the context into consideration. We define orthogonality judgements in the following manner:

\begin{definition}
    We say that an orthogonality judgement $\ORTH{\Gamma}{\Delta_1}{\vv{t}}{\Delta_2}{\vv{s}}{A}$ is valid when:
    \begin{itemize}
        \item The judgement $\TYP{\Gamma,\Delta_1}{\vv{t}}{A}$ is valid.
        \item The judgement $\TYP{\Gamma,\Delta_2}{\vv{s}}{A}$ is valid.
        \item For every $\sigma\in\sem{\Gamma,\Delta_1}, \tau\in\sem{\Gamma,\Delta_2}$ there are value distributions $\vv{v},\vv{w}$ such that $\vv{t}\ansubst{\sigma}{}\eval\vv{v}, \vv{s}\ansubst{\tau}{}\eval\vv{w}$ and $\vv{v}\perp\vv{w}$.
    \end{itemize}
\end{definition}

If both $\Delta_1$ and $\Delta_2$ are empty, we will note the judgement as $\SORTH{\Gamma}{\vv{t}}{\vv{s}}{A}$. We will be mostly interested in these cases.

\begin{table}[t]
    $
    \begin{array}{c}
    \infer[\snam{Axiom}]{\TYP{x_X:A}{x}{A}}{\basis{X}\leq A \vee X=\AbsBasis}\quad
    \infer[\snam{Sub}]{\TYP{\Gamma}{\vv{t}}{A'}}{
        \TYP{\Gamma}{\vv{t}}{A} & \SUB{A}{A'}
    }\\
    \noalign{\medskip}
    \infer[\snam{UnitLam}]{
        \TYP{\Gamma}{\sum_{i=1}^n \alpha_i (\Lam{x}{A}{\vv{t_i}})}{A\Arr B}
    }{\TYP{\Gamma,x_A: A}{\sum_{i=1}^{n}\alpha_i\vv{t_i}}{B}
    }\\
    \noalign{\medskip}
    \infer[\snam{App}]{\TYP{\Gamma,\Delta}{\vv{s}\,\vv{t}}{B}}{
        \TYP{\Gamma}{\vv{s}}{A\Arr B} & \TYP{\Delta}{\vv{t}}{A}
    }\ 
    \infer[\snam{GlobalPhase}]{\TYP{\Gamma}{e^{i\theta}\vv{t}}{A}}
    {\TYP{\Gamma}{\vv{t}}{A}}
    \\
    \noalign{\medskip}
    \infer[\snam{Pair}]{\TYP{\Gamma,\Delta}
        {\Pair{\vv{t}}{\vv{s}}}{A\times B}}{
        \TYP{\Gamma}{\vv{t}}{A}&\TYP{\Delta}{\vv{s}}{B}
    }\quad
    \infer[\snam{Weak}]{\TYP{\Gamma,x_A:B}{\vv{t}}{C}}{
        \TYP{\Gamma}{\vv{t}}{B}& \flat{A} & A\leq B
    }
    \\
    \noalign{\medskip}
    \infer[\snam{LetPair}]{\TYP{\Gamma,\Delta} 
        {\LetP{x}{B_1}{y}{B_2}{\vv{t}}{\vv{s}}}{C}}{
        \TYP{\Gamma}{\vv{t}}{A_1\times A_2}&
        \TYP{\Delta,x_{B_1}:A_1,y_{B_2}:A_2}{\vv{s}}{C}
    }\\
    \noalign{\medskip}
    \infer[\snam{LetTens}]{\TYP{\Gamma,\Delta}
        {\LetP{x}{B_1}{y}{B_2}{\vv{t}}{\vv{s}}}{\sharp C}}{
        \TYP{\Gamma}{\vv{t}}{\sharp(A_1\times A_2)}&
        \TYP{\Delta,x_{B_1}:\sharp A_1,y_{B_2}:\sharp A_2}{\vv{s}}{C}
    }\\
    \noalign{\medskip}
    \infer[\snam{Case}]{\TYP{\Gamma,\Delta}
        {\gencase{\vv{t}}{\vv{v_1}}{\vv{v_n}}{\vv{s_1}}{\vv{s_n}}}{A}}{
        \TYP{\Gamma}{\vv{t}}{\genbasis{\vv{v_i}}{i=1}{n}}&
        \forall i,\ \TYP{\Delta}{\vv{s_i}}{A}
    }\\
    \noalign{\medskip}
    \infer[\snam{UnitCase}]{\TYP{\Gamma,\Delta}
        {\gencase{\vv{t}}{\vv{v_1}}{\vv{v_n}}{\vv{s_1}}{\vv{s_n}}}{\sharp A}}{
        \TYP{\Gamma}{\vv{t}}{\sharp \genbasis{\vv{v_i}}{i=1}{n}}&
        \forall i\neq j,\ \SORTH{\Delta}{\vv{s_i}}{\vv{s_j}}{A}
    }\\
    \noalign{\medskip}
    \infer[\snam{Sum}]
        {\TYP{\Gamma}{\sum_{i=1}^{n} \vv{t_i}}{\sharp A}}
        {\forall i\neq j,\, \SORTH{\Gamma}{\vv{t_i}}{\vv{t_j}}{A} &
        \sum_{i=1}^{n}|\alpha_i|^2 = 1}
    \\
    \noalign{\medskip}
    \infer[\snam{Contr}]{\TYP{\Gamma,x_A:A}{\vv{t}\,[y:=x]}{B}}{
        \TYP{\Gamma,x_A:A,y_A:A}{\vv{t}}{B}&\flat{A}
    }\ 
    \infer[\snam{Equiv}]{\TYP{\Gamma}{\vv{s}}{A}}{
        \TYP{\Gamma}{\vv{t}}{A}& \vv t\equiv \vv s
    }\\
    \noalign{\medskip}
    \end{array}
    $

    \parbox{\linewidth}{Where the property $\flat$ is defined as: 
    \[\flat X \iff \forall \vv v, \vv w\in\sem{X}, ~ \vv{v}\neq \vv w \Rightarrow \scal{\vv v}{\vv w} = 0
    \]
    }
    \caption{Some valid typing rules}
    \label{tab:TypingRules}
\end{table}

The main result of this section, is the proof of validity of each of the rules presented in \Cref{tab:TypingRules}.

\begin{theorem}
    The rules in \Cref{tab:TypingRules} are valid.
\end{theorem}

\begin{proof}
    For each typing rule in \Cref{tab:TypingRules}~we have to show the typing judgement is valid starting from the premises:
    \begin{description}
    \item[Axiom] It is clear that $\sdom{x:A}\subseteq\{x\}=\dom{x:A}$. Moreover, given $\sigma\in\sem{x_B:A}$, we have $\sigma=\ansubst{\vv v/x}{B}$ for some $\vv{v}\in\sem{A}$. Therefore, $x\ansubst{\sigma}{}=x\ansubst{\vv v}{B}=\vv{v}\real A$.
    
    \item[Sub] Trivial since $\semr{A}\subseteq\semr{A'}$. 

    \item[UnitLam] If the hypothesis is valid, $\sdom{\Gamma,x_A:A}\subseteq \FV{\sum_{i=1}^{n}\alpha_i \vv{t_i}}\subseteq \dom{\Gamma,x_A:A}$. It follows that $\sdom{\Gamma}\subseteq \FV{\sum_{i=1}^{n}\alpha_i (\Lam{x}{A}{\vv{t_i}})}\subseteq \dom{\Gamma}$. Given $\sigma\in\sem{\Gamma}$, we want to show that $(\sum_{i=1}^{n}\alpha_i (\Lam{x}{A}{\vv{t_i}}))\ansubst{\sigma}{}\real A\Arr B$. Let $\vv v\in\sem{A}$, then:
    
    \begin{align*}
        (\sum_{i=1}^{n} \alpha_i(\Lam{x}{A}{\vv{t_i}}))\ansubst{\sigma}{} \vv v&= (\sum_{j=1}^{m} \beta_j (\sum_{i=1}^{n} \alpha_i (\Lam{x}{A}{\vv{t_i}}) [\sigma_i])) \vv{v} \\
        &= (\sum_{i=1}^{n}\sum_{j=1}^{m}\alpha_i\beta_j (\Lam{x}{A}{\vv{t_i}[\sigma_j]}))\vv v\\
        &\lra \sum_{i=1}^{n}\sum_{j=1}^{m}\alpha_i\beta_j \vv{t_i}[\sigma_j]\ansubst{\vv v/x}{A}\\
        &=\sum_{i=1}^{n}\alpha_i \vv{t_i}\ansubst{\sigma}{}\ansubst{\vv v/x}{A}\\
        &=(\sum_{i=1}^{n}\alpha_i \vv{t_i})\ansubst{\sigma}{}\ansubst{\vv v/x}{A}\qquad{\text{By \Cref{lem:distributiveSubstitution}}}
    \end{align*}
    
    Considering that $\ansubst{\sigma}{}\in\sem{\Gamma}$, then we have that $\ansubst{\sigma}{}\ansubst{\vv v/x}{A}\in\sem{\Gamma,x_A:A}$. Since we assume $\TYP{\Gamma, x_A:A}{\sum_{i=1}^{n}\alpha_i\vv{t_i}}{B}$, then $\vv{t_i}\ansubst{\sigma}{}\ansubst{\vv v/x}{A}\real B$. Finally, we can conclude that the distribution: $\sum_{i=1}^{n}\alpha_i (\Lam{x}{A}{\vv{t_i}})\in\sem{A\Arr B}$.

    \item[App] If the hypotheses are valid, then:
    \begin{itemize}
        \item $\sdom{\Gamma}\subseteq \FV{\vv s}\subseteq \dom{\Gamma}$ and $\vv s \ansubst{\sigma_\Gamma}{}\Vdash A\Arr B\ \forall \sigma_\Gamma\in\sem{\Gamma}$.
        \item $\sdom{\Delta}\subseteq \FV{\vv t}\subseteq \dom{\Delta}$ and $\vv t\ansubst{\sigma_\Delta}{}\Vdash A\ \forall\sigma_\Delta\in\sem{\Delta}$.
    \end{itemize}
    
    From this, we can conclude that $\sdom{\Gamma,\Delta}\subseteq \FV{\vv s \vv t}\subseteq \dom{\Gamma,\Delta}$. Given $\sigma\in\sem{\Gamma,\Delta}$, we can observe that $\sigma=\sigma_\Gamma,\sigma_\Delta$ for some $\sigma_\Gamma\in\sem{\Gamma}$ and $\sigma_\Delta\in\sem{\Delta}$. Then we have:
    
    \begin{align*}
        (\vv{t}\vv{s})\ansubst{\sigma}{} &= (\vv{t}\vv{s})\ansubst{\sigma_\Gamma}{}\ansubst{\sigma_\Delta}{}\\
        &=(\sum_{i=i}^{n}\alpha_i (\vv{t}\vv{s})[\sigma_{\Gamma i}])\ansubst{\sigma_\Delta}{}\\
        &=\sum_{j=1}^{m} \beta_j (\sum_{i=1}^{n} \alpha_i (\vv{t} \vv{s})[\sigma_{\Gamma i}])[\sigma_{\Delta j}]\\
        &=\sum_{i=1}^{n}\sum_{j=1}^{m} \alpha_i \beta_j \vv{t}\,[\sigma_{\Gamma i}][\sigma_{\Delta j}] \vv{s}\,[\sigma_{\Gamma i}][\sigma_{\Delta j}]\\
        &=\sum_{i=1}^{n}\sum_{j=1}^{m} \alpha_i \beta_j \vv{t}\,[\sigma_{\Gamma i}]\vv{s}\,[\sigma_{\Delta j}]\\
        &\equiv (\sum_{i=1}^{n}\alpha_i\vv{t}[\sigma_{\Gamma i}])(\sum_{j=1}^{m} \beta_j \vv{s}[\sigma_{\Delta j}])\\
        &=\vv{t}\ansubst{\sigma_\Gamma}{} \vv{s}\ansubst{\sigma_\Delta}{}\\
        &\eval (e^{i\theta_{1}} \vv{v}) (e^{i\theta_{2}} \vv{w})\qquad\text{Where: } \vv{v}\in\sem{A\Arr B}, \vv{w}\in\sem{A}\\
        &\equiv e^{i\theta} (\vv{v} \vv{w})\qquad\text{with: }\theta=\theta_1 + \theta_2\\
        &\lraneq e^{i\theta}\vv r\qquad\text{where: } \vv{r}\real B
    \end{align*}
    
    Then we can conclude that $(\vv{t}\vv{s})\ansubst{\sigma}{}\real B$.
    
    \item[Pair] If the hypotheses are valid, then:

    \begin{itemize}
        \item $\sdom{\Gamma}\subseteq \FV{\vv s}\subseteq \dom{\Gamma}$ and $\vv s \ansubst{\sigma_\Gamma}{}\Vdash A\ \forall \sigma_\Gamma\in\sem{\Gamma}$.
        \item $\sdom{\Delta}\subseteq \FV{\vv t}\subseteq \dom{\Delta}$ and $\vv t\ansubst{\sigma_\Delta}{}\Vdash B\ \forall \sigma_\Delta\in\sem{\Delta}$.
    \end{itemize}
    
    From this, we can conclude that $\sdom{\Gamma,\Delta}\subseteq \FV{(\vv s, \vv t)}\subseteq \dom{\Gamma,\Delta}$. Given $\sigma\in\sem{\Gamma,\Delta}$, we can observe that $\sigma=\sigma_\Gamma,\sigma_\Delta$ for some  $\sigma_\Gamma\in\sem{\Gamma}$ and $\sigma_\Delta\in\sem{\Delta}$. Then we have:

    \begin{align*}
        \Pair{\vv{t}}{\vv{s}}\ansubst{\sigma}{} &= \Pair{\vv{t}}{\vv{s}}\ansubst{\sigma_\Gamma}{}\ansubst{\sigma_\Delta}{}\\
        &=\sum_{j=1}^{m} \beta_j (\sum_{i=1}^{n} \alpha_i \Pair{\vv{t}}{\vv{s}}[\sigma_{\Gamma i}])[\sigma_{\Delta j}]\\
        &\equiv\sum_{i=1}^{n}\sum_{j=1}^{m} \alpha_i \beta_j \Pair{\vv{t}\,[\sigma_{\Gamma i}][\sigma_{\Delta j}]}{\vv{s}\,[\sigma_{\Gamma i}][\sigma_{\Delta j}]}\\
        &=\sum_{i=1}^{n}\sum_{j=1}^{m} \alpha_i \beta_j \Pair{\vv{t}\,[\sigma_{\Gamma i}]}{\vv{s}\,[\sigma_{\Delta j}]}\\
        &=\Pair{\sum_{i=1}^{n} \alpha_i \vv{t}\, [\sigma_{\Gamma i}]}{\sum_{j=1}^{m} \beta_j \vv{s}\, [\sigma_{\Delta j}]}\\
        &=\Pair{\vv{t}\ansubst{\sigma_\Gamma}{}}{\vv{s}\ansubst{\sigma_\Delta}{}}\\
        &\eval \Pair{e^{i\theta_1}\vv v}{e^{i\theta_2}\vv w}\qquad\text{where: }\vv{v}\in\sem{A}, \vv{w}\in\sem{B}\\
        &= e^{i\theta} \Pair{\vv{v}}{\vv{w}}\qquad\text{where: }\vv{v}\in\sem{A},\vv{w}\in\sem{B}
    \end{align*}
    
    From this we can conclude that $\Pair{\vv t}{\vv{s}}\ansubst{\sigma}{}\real A\times B$. Finally, $\TYP{\Gamma,\Delta}{\Pair{\vv{t}}{\vv{s}}}{A\times B}$
    
    \item[LetPair] If the hypotheses are valid, then:
    \begin{itemize}
        \item $\sdom{\Gamma}\subseteq \FV{\vv t} \subseteq \dom{\Gamma}$ and $\vv t \ansubst{\sigma_\Gamma}{}\Vdash A\times B\ \forall \sigma_\Gamma\in\sem\Gamma$
        \item $\sdom{\Delta, {x_1}_{B_1}:A_1, {x_2}_{B_2}:A_2}\subseteq\FV{\vv s}$
        \item $\FV{\vv{s}}\subseteq \dom{\Delta,{x_1}_{B_1}:A_1, {x_2}_{B_2}:A_2}$
        \item $\vv s \ansubst{\sigma_\Delta}{}\Vdash C\ \forall \sigma_\Delta\in\sem{\Delta, {x_1}_{B_1}:A_1, {x_2}_{B_2}:A_2}$
    \end{itemize}
    From this, we can conclude that:
    \begin{itemize}
        \item $\sdom{\Gamma,\Delta}\subseteq\FV{\LetP{x}{B_1}{y}{B_2}{\vv{s}}{\vv{t}}}$
        \item $\FV{\LetP{x}{B_1}{y}{B_2}{\vv{s}}{\vv{t}}}\subseteq\dom{\Gamma,\Delta}$
    \end{itemize}
    
    Given $\sigma\in\sem{\Gamma,\Delta}$, we have that $\ansubst{\sigma}{}=\ansubst{\sigma_\Gamma}{},\ansubst{\sigma_\Delta}{}$ for some $\sigma_\Gamma\in\sem\Gamma$ and $\sigma_\Delta\in\sem\Delta$. Then we have:
    \begin{align*}
        (&\LetP{x}{B_1}{y}{B_2}{\vv{t}}{\vv{s}})\ansubst{\sigma}{} = \\
        &(\LetP{x}{B_1}{y}{B_2}{\vv{t}}{\vv{s}})\ansubst{\sigma_\Gamma}{}\ansubst{\sigma_\Delta}{}\\
        &= \sum_{i=1}^{n}\sum_{j=1}^{m}\alpha_i\beta_j(\LetP{x}{B_1}{y}{B_2}{\vv{t}}{\vv{s}})[\sigma_{\Gamma i}][\sigma_{\Delta j}]\\
        &\equiv \LetP{x}{B_1}{y}{B_2}{\sum_{i=1}^{n}\alpha_i[\sigma_{\Gamma i}]\vv{t}}{\sum_{j=1}^{m}\beta_j \vv{s}[\sigma_{\Delta j}]}\\
        &= \LetP{x}{B_1}{y}{B_2}{\vv{t}\ansubst{\sigma_\Gamma}{}}{\vv{s}\ansubst{\sigma_\Delta}{}}\\
        &\eval \LetP{x}{B_1}{y}{B_2}{e^{i\theta} \Pair{\vv{v}}{\vv{w}}}{\vv{s}\ansubst{\sigma_\Delta}{}}\\
        &\hspace*{4cm}{\text{Where: }}\vv{v}\in\sem{A},\vv{w}\in\sem{B}\\
        &\lraneq e^{i\theta_1} (\vv{s}\ansubst{\sigma_\Delta}{}\ansubst{\Pair{\vv{v}}{\vv{w}}/x_1\otimes x_2}{B_1\otimes B_2})\\
        &= e^{i\theta_1} (\vv{s}\ansubst{\sigma_\Delta}{}\ansubst{\vv{v}/x_1}{B_1}\ansubst{\vv{w}/x_2}{B_2})\\
        &\eval e^{i\theta_1}  (e^{i\theta_2}  \vv{u})\qquad\text{where: }\vv{u}\in\sem{C}\\
        &\equiv e^{i\theta}  \vv{u}\qquad\text{where: }\theta=\theta_1 + \theta_2
    \end{align*}
    
    Since $\ansubst{\sigma_\Delta}{}\ansubst{\vv{v}/x_1}{B_1}\ansubst{\vv{w}/x_2}{B_2}\in\sem{\Delta,{x_1}_{B_1}:A_1,{x_2}_{B_2}:A_2}$, then we can conclude that $(\LetP{x}{B_1}{y}{B_2}{\vv{t}}{\vv{s}})\ansubst{\sigma}{}\real C$.

    \item[LetTens] If the hypotheses are valid then:
    \begin{itemize}
        \item $\sdom{\Gamma}\subseteq \FV{\vv t} \subseteq \dom{\Gamma}$ and $\vv t \ansubst{\sigma}{}\Vdash A\otimes B\ \forall \sigma\in\sem\Gamma$
        \item $\sdom{\Delta, {x_1}_{B_1}:\sharp A_1, {x_2}_{B_2}:\sharp A_2}\subseteq \FV{\vv s}$
        \item $\subseteq \dom{\Delta,{x_1}:{B_1}, {x_2}_{B_2}:A_2}$
        \item $\vv s \ansubst{\sigma}{}\Vdash \sharp C\ \forall \sigma\in\sem{\Delta, {x_1}_{B_1}:\sharp A_1, {x_2}_{B_2}:\sharp A_2}$
    \end{itemize}
    
    From this we can conclude that:
    \begin{itemize}
        \item $\sdom{\Gamma,\Delta}\subseteq\FV{\LetP{x_1}{B_1}{x_2}{B_2}{\vv{t}}{\vv{s}}}$
        \item $\FV{\LetP{x_1}{B_1}{x_2}{B_2}{\vv{t}}{\vv{s}}}\subseteq\dom{\Gamma,\Delta}$
    \end{itemize}
    
    Given $\sigma\in\sem{\Gamma,\Delta}$, we have that $\ansubst{\sigma}{}=\ansubst{\sigma_\Gamma}{},\ansubst{\sigma_\Delta}{}$ for some $\sigma_\Gamma\in\sem\Gamma$ and $\sigma_\Delta\in\sem\Delta$. Using the first hypothesis we have that, $\vv t\ansubst{\sigma_\Gamma}{}\real \sharp(A_1\times A_2)$, from \Cref{thm:SharpCharacterization} we have that:
    
    \[\vv t\ansubst{\sigma_\Gamma}{}\eval e^{i\theta_1}\vv{u}=e^{i\theta_1}(\sum_{k=1}^{l} \gamma_k \Pair{\vv{v_k}}{\vv{u_k}})\] 
    
    With:
    \begin{itemize}
        \item $\sum_{k=1}^{l} |\gamma_k|^2 = 1$
        \item $\forall k,\ \vv{v_k}\in\sem{A_1},\ \vv{u_k}\in\sem{A_2}$
        \item $\forall k\neq l, \scal{\Pair{\vv{v_k}}{\vv{u_k}}}{\Pair{\vv{v_l}}{\vv{u_l}}}= 0$
    \end{itemize}
    
    Then:
    \begin{align*}
        (&\LetP{x_1}{B_1}{x_2}{B_2}{\vv{t}}{\vv{s}})\ansubst{\sigma}{} \\
        &= \LetP{x_1}{B_1}{x_2}{B_2}{\vv{t}}{\vv{s}}\ansubst{\sigma_\Gamma}{}\ansubst{\sigma_\Delta}{}\\
        &=\sum_{i=1}^{n}\sum_{j=1}^{m}\LetP{x_1}{B_1}{x_2}{B_2}{\vv{t}}{\vv{s}}\ [\sigma_{\Gamma i}][\sigma_{\Delta j}]\\
        &\equiv \LetP{x_1}{B_1}{x_2}{B_2}{\sum_{i=1}^{n}\alpha_i\vv{t}\ [\sigma_{\Gamma i}]}{\sum_{j=1}^{m}\beta_j \vv{s}\ [\sigma_{\Delta j}]}\\
        &=\LetP{x_1}{B_1}{x_2}{B_2}{\vv{t}\ansubst{\sigma_\Gamma}{}}{\vv{s}\ansubst{\sigma_\Delta}{}}\\
        &\eval\LetP{x_1}{B_1}{x_2}{B_2}{e^{i\theta_1}\vv{u}}{\vv{s}\ansubst{\sigma_\Delta}{}}\\
        &\lraneq e^{i\theta_1}(\vv{s}\ansubst{\sigma_\Delta}{}\ansubst{\vv{u}/x_1\otimes x_2}{B_1\otimes B_2})\\
        &=e^{i\theta_1} (\sum_{k=1}^{l}\gamma_k\vv{s}\ansubst{\sigma_\Delta}{}\ansubst{\vv{v_k}/x}{B_1}\ansubst{\vv{u_k}/y}{B_2})\\
        &\eval e^{i\theta_1} (\sum_{k=1}^{l}\gamma_k e^{i\rho_k} \vv{w_k})\\
    \end{align*}

    Since $\vv{s}\ansubst{\sigma_\Delta}{}\ansubst{\vv{v_k}/x}{B_1}\ansubst{\vv{u_k}/y}{B_2}\in\sem{\Delta, x_{B_1}:\sharp A_1, y_{B2}:\sharp A_2}$, for every $k$, then $\vv{w_k}\in\sem{C}$. It remains to be seen that the term has norm-$1$, $\|\sum_{k=1}^{l}\gamma_k e^{i\rho_k} \vv{w_k}\|=1$. For that, we observe:
    \begin{align*}
        \|&\sum_{k=1}^{l}\gamma_k e^{i\rho_k} \vv{w_k}\| \\
        &= \scal{\sum_{k=1}^{l}\alpha_i e^{i\rho_k} \vv{w_k}}{\sum_{k'=1}^{l}\gamma_{k'} e^{i\rho_{k'}} \vv{w_{k'}}}\\
        &= \sum_{k=1}^{l}\sum_{k'}^{l}\overline{\gamma_k e^{i\rho_k}}\  \gamma_{k'} e^{i\rho_{k'}}\scal{\vv{w_k}}{\vv{w_{k'}}}\\
        &=\sum_{k=1}^{l}\sum_{k'=1}^{l}\overline{\gamma_k e^{i\rho_k}}\ \gamma_{k'} e^{i\rho_{k'}} \scal{\vv{v_k}}{\vv{v_{k'}}}\scal{\vv{u_k}}{\vv{u_{k'}}}\quad(\text{from \Cref{lem:UnitPreserTens}})\\
        &= \sum_{k=1}^{k}\sum_{k'=1}^{l}\overline{\gamma_k e^{i\rho_k}}\  \gamma_{k'} e^{i\rho_{k'}} \scal{\Pair{\vv{u_k}}{\vv{v_k}}}{\Pair{\vv{u_{k'}}}{\vv{v_{k'}}}}\quad(\text{from \Cref{prop:InnerProdPairs}})\\
        &=\sum_{k=1}^n \overline{\gamma_k e^{i\rho_k}}\ \gamma_k e^{i\rho_k} \scal{\Pair{\vv{v_k}}{\vv{u_k}}}{\Pair{\vv{v_k}}{\vv{u_k}}} \\
        & \quad + \sum_{k,k'=1; k\neq k'}^n \overline{\gamma_k e^{i\rho_k}}\  \gamma_{k'} e^{i\rho_{k'}} \scal{\Pair{\vv{v_k}}{\vv{u_k}}}{\Pair{\vv{v_{k'}}}{\vv{u_{k'}}}}\\
        &= \sum_{k=1}^n \overline{\gamma_k e^{i\rho_k}}\ \gamma_k e^{i\rho_k} + 0 \\
        &= \sum_{k=1}^{l} |\gamma_k|^2 |e^{i\rho_k}|^2 = 1
    \end{align*}

    Then $\sum_{i=1}^{n}\alpha_i\vv{w_i}\in\sem{\sharp C}$. Finally, we can conclude that: 
    \[(\LetP{x_1}{B_1}{x_2}{B_2}{\vv{t}}{\vv{s}})\ansubst{\sigma}{}\real{\sharp C}\]

    \item[Case] If the hypotheses are valid then:
    \begin{itemize}
        \item $\sdom{\Gamma}\subseteq \FV{\vv{t}}\subseteq \dom{\Gamma}$
        \item For every $\sigma_\Gamma\in\sem{\Gamma}$, $\vv{t}\ansubst{\sigma_\Gamma}{}\real\genbasis{\vv{v_i}}{i=1}{n}$
        \item For every $i\in\{0,\dotsb ,n\}, \sdom{\Delta}\subseteq \FV{\vv{s_i}}\subseteq \dom{\Delta}$
        \item For every $i\in\{0,\dotsb ,n\}, \sigma_\Delta\in\sem{\Delta}$, $\vv{s_i}\ansubst{\sigma_\Delta}{}\real A$
    \end{itemize}

    From this we can conclude that:
    
    \begin{itemize}
        \item $\sdom{\Gamma,\Delta}\subseteq \FV{\gencase{\vv{t}}{\vv{v_1}}{\vv {v_n}}{\vv{s_1}}{\vv{s_n}}}$
        \item $\FV{\gencase{\vv{t}}{\vv{v_1}}{\vv {v_n}}{\vv{s_1}}{\vv{s_n}}}\subseteq \dom{\Gamma,\Delta}$
    \end{itemize}


    
    Then, given $\sigma\in\sem{\Gamma,\Delta}$, we have that $\ansubst{\sigma}{}=\ansubst{\sigma_\Gamma}{}\ansubst{\sigma_\Delta}{}$ for some $\sigma_\Gamma\in\sem{\Gamma}$ and $\sigma_\Delta\in\sem{\Delta}$. Using the first hypothesis we have that, $\vv{t}\ansubst{\sigma_\Gamma}{}\eval e^{i\theta_1}\vv{v_k}$ for some $k\in\{1,\dotsb ,n\}$. From the second hypothesis we have that $\vv{s_i}\ansubst{\sigma_\Delta}{}\eval e^{i\rho_i}\vv{u_i}\in\sem{A}$ for $i\in\{1,\dotsb , n\}$. Therefore:

    \begin{align*}
        (&\gencase{\vv{t}}{\vv{v_1}}{\vv{v_n}}{\vv{s_1}}{\vv{s_n}})\ansubst{\sigma}{}\\ 
        &= (\gencase{\vv{t}}{\vv{v_1}}{\vv{v_n}}{\vv{s_1}}{\vv{s_n}})\ansubst{\sigma_\Gamma}{}\ansubst{\sigma_\Delta}{}\\
        &= (\sum_{i=1}^{n}\alpha_i \gencase{\vv{t}[\sigma_{\Gamma i}]}{\vv{v_1}}{\vv{v_n}}{\vv{s_1}}{\vv{s_n}})\ansubst{\sigma_\Delta}{} \\
        &\equiv (\gencase{\sum_{i=1}^{n} \alpha_i \vv{t}[\sigma_{\Gamma i}]}{\vv{v_1}}{\vv{v_n}}{\vv{s_1}}{\vv{s_n}})\ansubst{\sigma_\Delta}{}\\
        &=(\gencase{\vv{t}\ansubst{\sigma_\Gamma}{}}{\vv{v_1}}{\vv{v_n}}{\vv{s_1}}{\vv{s_n}})\ansubst{\sigma_\Delta}{}\\
        &\eval(\gencase{e^{i\theta_1}\vv{v_k}}{\vv{v_1}}{\vv{v_n}}{\vv{s_1}}{\vv{s_n}})\ansubst{\sigma_\Delta}{}\\
        &\lraneq e^{i\theta_1}(\vv{s_k}\ansubst{\sigma_\Delta}{})\\
        &\eval e^{i\theta_1}(e^{i\rho_k} \vv{u_k})\qquad\text{Where: }\vv{u_k}\in\sem{A}\\
        &\equiv e^{i\theta} \vv{u_k}\qquad\text{With: }\theta=\theta_1 +\theta_2
    \end{align*}
    
    Since we pose no restriction on $k$, we can conclude that:
    \[(\gencase{\vv{t}}{\vv{v_1}}{\vv{v_n}}{\vv{s_1}}{\vv{s_n}})\ansubst{\sigma}{}\real A\]


    \item[UnitCase] If the hypotheses are valid, then:
    \begin{itemize}
        \item $\sdom{\Gamma}\subseteq \FV{\vv{t}}\subseteq \dom{\Gamma}$
        \item For every $\sigma_\Gamma\in\sem{\Gamma}$, $\vv{t}\ansubst{\sigma_\Gamma}{}\real\sharp\genbasis{\vv{v_i}}{i=1}{n}$
        \item For every $i$, $\sdom{\Delta}\subseteq \FV{\vv{s_i}}\subseteq \dom{\Delta}$
        \item For every $i\in\{0,\dotsb ,n\}, \sigma_\Delta\in\sem{\Delta}$, $\vv{s_i}\ansubst{\sigma_\Delta}{}\real A$
    \end{itemize}
    
    From this we can conclude that:
    
    \begin{itemize}
        \item $\sdom{\Gamma,\Delta}\subseteq \FV{\gencase{\vv{t}}{\vv{v_1}}{\vv{v_n}}{\vv{s_1}}{\vv{s_n}}}$
        \item $\FV{\gencase{\vv{t}}{\vv{v_1}}{\vv{v_n}}{\vv{s_1}}{\vv{s_n}}}\subseteq \dom{\Gamma,\Delta}$
    \end{itemize}
    
    Then, given $\sigma\in\sem{\Gamma,\Delta}$, we have that $\ansubst{\sigma}{}=\ansubst{\sigma_\Gamma}{}\ansubst{\sigma_\Delta}{}$ for some $\sigma_\Gamma\in\sem{\Gamma}$ and $\sigma_\Delta\in\sem{\Delta}$. Using the first hypothesis we have that, $\vv{t}\ansubst{\sigma_\Gamma}{}\real\sharp\genbasis{\vv{v_i}}{i=1}{n}$, then $\vv{t}\ansubst{\sigma_\Gamma}{}\eval e^{i\theta_1} \vv{u}=e^{i\theta_1} (\sum_{i=1}^{n}\beta_i \vv{v_i})$ where $\sum_{i=1}^{n}|\beta_i|^2$. From the second hypothesis we have that $\vv{s_i}\ansubst{\sigma_\Delta}{}\eval e^{i\rho_i} \vv{u_i}\in\sem{A}$ for $i\in\{1,\dotsb ,n\}$ and $u_i\perp u_j$ if $i\neq j$. Therefore:

    \begin{align*}
        (&\gencase{\vv{t}}{\vv{v_1}}{\vv{v_n}}{\vv{s_1}}{\vv{s_n}})\ansubst{\sigma}{}\\ 
        &= (\gencase{\vv{t}}{\vv{v_1}}{\vv{v_n}}{\vv{s_1}}{\vv{s_n}})\ansubst{\sigma_\Gamma}{}\ansubst{\sigma_\Delta}{}\\
        &=(\sum_{i=1}^{n}\alpha_i \gencase{\vv{t}[\sigma_{\Gamma i}]}{\vv{v_1}}{\vv{v_n}}{\vv{s_1}}{\vv{s_n}})\ansubst{\sigma_\Delta}{} \\
        &\equiv (\gencase{\sum_{i=1}^{n} \alpha_i \vv{t}[\sigma_{\Gamma i}]}{\vv {v_1}}{\vv{v_n}}{\vv{s_1}}{\vv{s_n}})\ansubst{\sigma_\Delta}{}\\
        &=(\gencase{\vv{t}\ansubst{\sigma_\Gamma}{}}{\vv{v_1}}{\vv{v_n}}{\vv{s_1}}{\vv{s_n}})\ansubst{\sigma_\Delta}{}\\
        &\eval(\gencase{e^{i\theta_1} \vv{u}}{\vv{v}}{\vv{w}}{\vv{s_1}}{\vv{s_2}})\ansubst{\sigma_\Delta}{}\\
        &\lraneq e^{i\theta_1} (\sum_{i=1}^{n}\beta_i s_i)\ansubst{\sigma_\Delta}{}\\
        &= e^{i\theta_1} (\sum_{j=1}^{n}\delta_j (\sum_{i=1}^{n}\beta_i \vv{s_i})[\sigma_{\Delta j}])\\
        &= e^{i\theta_1} (\sum_{j=1}^{n}\delta_j (\sum_{i=1}^{n}\beta_i \vv{s_i}[[\sigma_{\Delta j}]]))\\
        &\equiv e^{i\theta_1} (\sum_{i,j=1}^{n}\beta_i\delta_j\vv{s_i}[\sigma_{\Delta j}])\\
        &= e^{i\theta_1} (\sum_{i=1}^{n}\beta_i \vv{s_i}\ansubst{\sigma_\Delta}{})\\
        &\eval e^{i\theta_1} (\sum_{i=1}^{n}\beta_i e^{i\rho_i} \vv{u_i})
    \end{align*}
    
    It remains to be seen that: $\|\sum_{i=1}^{n}\beta_i e^{i\rho_i} \vv{u_i}\|=1$:
    \begin{align*}
        \|\sum_{i=1}^{n}\beta_i e^{i\rho_i} \vv{u_i}\| &= \scal{\sum_{i=1}^{n}\beta_i e^{i\rho_i} \vv{u_i}}{\sum_{i=1}^{n}\beta_i e^{i\rho_i} \vv{u_i}}\\
        &= \sum_{i,j=1}^{n}\overline{\beta_i e^{i\rho_i}}\beta_j e^{i\rho_j} \scal{\vv{u_i}}{\vv{u_j}}\\
        &= \sum_{i=1}^{n}\overline{\beta_i e^{i\rho_i}}\beta_i e^{i\rho_i} \scal{\vv{u_i}}{\vv{u_i}}\\
        &\qquad + \sum_{i,j=1; i\neq j}^{n}\overline{\beta_i e^{i\rho_i}}\beta_j e^{i\rho_j} \scal{\vv{u_i}}{\vv{u_j}}\\
        &= \sum_{i=1}^{n}|\beta_i|^2 |e^{i\rho_i}|^2  + 0\\
        &= \sum_{i=1}^{n}|\beta_i|^2 = 1
    \end{align*}

    Then we can conclude that $\sum_{i=1}^{n}\beta_i e^{i\rho_i}\vv{u_i}\in\sem{\sharp A}$ and finally:
    \[
        (\gencase{\vv{t}}{\vv{v_1}}{\vv{v_n}}{\vv{s_1}}{\vv{s_n}})\ansubst{\sigma}{}\real\sharp A
    \]

    \item[Sum] If the hypothesis is valid then for every $i$, $\sdom{\Gamma}\subseteq\FV{\vv{t_i}}\subseteq\dom{\Gamma}$.
    
    From this we can conclude that $\sdom{\Gamma}\subseteq\sum_{i=1}^{n}\alpha_i \vv{t_i}\subseteq\dom{\Gamma}$. Given $\sigma\in\sem{\Gamma}$, we have for every $i$, $\vv{t_i}\ansubst{\sigma}{}\eval e^{i\rho_i} \vv{v_i}$ where $\vv{v_i}\in\sem{A}$. Moreover, for every $i\neq j$, $\vv{v_i}\perp\vv{v_j}$ and $\sum_{i=1}^{n}|\alpha_i|^2=1$. Then:
    \begin{align*}
    (\sum_{i=1}^{n}\alpha_i\vv{t_i})\ansubst{\sigma}{} 
    &= \sum_{j=1}^{m}\beta_j(\sum_{i=1}^{n}\alpha_i \vv{t_i})[\sigma_j]\\
    &\equiv \sum_{i=1}^{n} \alpha_i \sum_{j=1}^{m} \beta_j \vv{t_i}[\sigma_j]\\
    &=\sum_{i=1}^{n} \alpha_i \vv{t_i}\ansubst{\sigma}{}\\
    &\eval \sum_{i=1}^{n} \alpha_i e^{i\rho_i} \vv{v_i}\\
    \end{align*}

    It remains to be seen that $\|\sum_{i=1}^{n} \alpha_i e^{i\rho_i} \vv{v_i}\|=1$. But:
    \begin{align*}
    &\|\sum_{i=1}^{n} \alpha_i e^{i\rho_i} \vv{v_i}\| \\
    &=\scal{\sum_{i=1}^{n} \alpha_i e^{i\rho_i}\vv{v_i}}{\sum_{i=1}^{n} \alpha_i e^{i\rho_i} \vv{v_i}}\\
    &= \sum_{i=i}^{n}\sum_{j=1}^{n} \overline{\alpha_i e^{i\rho_i}}\alpha_j e^{i\rho_j} \scal{\vv{v_i}}{\vv{v_j}}\\
    &=\sum_{i=1}^{n} \overline{\alpha_i e^{i\rho_i}}\alpha_i e^{i\rho_i} \scal{\vv{v_i}}{\vv{v_i}} + \sum_{\substack{i,j=1\\i\neq j}}^{n} \overline{\alpha_i e^{i\rho_i}}\alpha_j e^{i\rho_j} \scal{\vv{v_i}}{\vv{v_j}}\\
    &=\sum_{i=1}^{n}|\alpha_i|^2 |e^{i\rho_i}|^2+ 0\\
    &=\sum_{i=1}^{n}|\alpha_i|^2 = 1\\
    \end{align*}

    Then we can conclude that $\sum_{i=1}^{n}\alpha_i e^{i\rho_i}\vv{v_i}\in\sem{\sharp A}$ and finally $(\sum_{i=1}^{n}\alpha_i\vv{t_i})\ansubst{\sigma}{}\real\sharp A$.

    \item[Weak] Given $\sigma\in\sem{\Gamma,x_A:B}$, we observe that $\ansubst{\sigma}=\ansubst{\sigma_\Gamma}{}\ansubst{\vv{v}/x}{A}$ for some $\sigma_\Gamma\in\sem{\Gamma}$ and $\vv{v}\in\sem{B}$. Using the first hypothesis, we know that $\vv{t}\ansubst{\sigma_\Gamma}{}\eval e^{i\theta}\vv{w}$ where $\vv{w}\in\sem{B}$. Then we have:
    \[
    \vv{t}\ansubst{\sigma}{}=\vv{t}\ansubst{\sigma_\Gamma}{}\ansubst{\vv{v}/x}{A}\eval e^{i\theta}\vv{w}\ansubst{\vv{v}/x}{A}
    \]
    Since $\vv{v}\in\sem{A}$, $\vv{w}\ansubst{\vv{v}/x}{A}=\vv{w}[\vv{v}/x]=\vv{w}$ and $\vv{w}\in\sem{B}$, we can finally conclude that $\vv{t}\ansubst{\sigma}{}\real B$.

    \item[Contr] If the hypothesis is valid, we have that $\sdom{\Gamma, x_A:A, y_A:A}\subseteq\FV{\vv{t}}\subseteq\dom{\Gamma,x_A:A, y_A:A}$ and given $\sigma\in\sem{\Gamma,x_A:A, y_A:A}$, then $\vv{t}\ansubst{\sigma}{}\in\sem{B}$. Since we assume $\flat A$, we have that $\sdom{\Gamma,x_A:A, y_A:A}=\sdom{\Gamma,x_A:A}$. Therefore:
    
    \[
    \sdom{\Gamma,x_A:A}\subseteq\FV{\vv{t}}[x/y]\subseteq\dom{\Gamma,x_A:A}
    \]

    Given $\sigma\in\sem{\Gamma,x_A:A}$, we observe that $\ansubst{\sigma}{}=\ansubst{\vv{v}/x}{A}\ansubst{\sigma_\Gamma}{}$ with $\sigma_\Gamma\in\sem{\Gamma}$ and $\vv{v}\in\sem{A}$. Since $\vv{v}\in\sem{A}$, we know that $\vv{t}[\vv v/z] =\vv{t}\ansubst{\vv{v}/z}{A}$ for any variable $z$. Then we have:
    \begin{align*}
        \vv{t}[x/y]\ansubst{\sigma}{} &= \vv{t}[x/y]\ansubst{\vv{v}/x}{A}\ansubst{\sigma_\Gamma}{}\\
        &=\vv{t}[x/y][\vv{v}/x]\ansubst{\sigma_\Gamma}{}\\
        &=\vv{t}[\vv{v}/y][\vv{v}/x]\ansubst{\sigma_\Gamma}{}\\
        &=\vv{t}\ansubst{\vv{v}/y}{A}\ansubst{\vv{v}/x}{A}\ansubst{\sigma_\Gamma}{}    
    \end{align*}
    
    Since $\ansubst{\vv{v}/y}{A}\ansubst{\vv{v}/x}{A}\ansubst{\sigma}{}\in\sem{\Gamma,x_A:A,y_A:A}$, we get:
    \[\vv{t}\ansubst{\vv{v}/y}{}\ansubst{\vv{v}/x}{A}\ansubst{\sigma_\Gamma}{}\eval e^{i\theta}\vv{w}\in\sem{B}\]
    Then we can finally conclude that $\vv{t}[x/y]\ansubst{\sigma}{}\real B$.

    \item[Equiv] It follows from definition and the fact that the reduction commutes with the congruence relation.
    
    \item[GlobalPhase] It follows from the definition of type realizers.
    \end{description}
\end{proof}

{\color{red}LLEGUÃ HASTA ACÃ

TODO: AGREGAR MÃS PROSA Y DEMOSTRACIÃN DE SUBJECT REDUCTION.}



\section{Examples}\label{sec:examples}

In this chapter we examine two use cases for the $\lambdaB$ calculus. First, taking advantage of the basis types defined in the type algebra, we are able to give a more expressive type to the term encoding Deutsch's algorithm. Second, we make use of the deferred measurement principle and pattern matching from the $\mathsf{case}$ constructor to write a descriptive term encoding the quantum teleportation protocol. 

\subsection{Deutsch's algorithm}

The Deutsch-Josza algorithm is a small example designed to showcase a problem which is solved exponentially faster by a quantum computer over a classical one. In it, we take as input a black box oracle which encodes a function $f:\{0,1\}^n\to\{0,1\}$. This function can be either \emph{constant} or \emph{balanced} (It outputs $0$ for exactly half the inputs and $1$ for the other half). The task to solve is to determine under which of the two classes the oracle falls.

In this section we will focus on the case where $n=1$, the original formulation of Deutsch's algorithm. However, this results can be generalised to any arbitrary $n$. The quantum circuit implementing the algorithm is the following:

\begin{align*}
    \Qcircuit @C=1em @R=.7em {
     \lstick{\ket{0}} & \qw & \gate{H} & \multigate{1}{U_f} & \qw & \gate{H} & \meter \\
     \lstick{\ket{1}} & \qw & \gate{H} & \ghost{U_f} & \qw & \qw & \qw
    }
\end{align*}

For a detailed discussion on the logic and operation of the algorithm, see~\cite{Deutsch1992RapidSO}. We will do a comparison between Deutsch's algorithm written in different bases and see what information we can glean from the typing of the terms.

We first define the terms for the algorithm. The top level $\mathsf{Deutsch}$ abstraction, takes an oracle $U_f$  which inputs two qubits $\ket{x y}$ and outputs $\ket{x (y\oplus f(x))}$ where $\oplus$ denotes addition modulo 2. The circuit will output $\ket{0}$ on the first qubit if the function $f$ is balanced 
% TODO: Incluir en el apÃ©ndice los juicios de tipado para los tÃ©rminos
\begin{table}
    \small
    \begin{align*}
        \mathsf{Deutsch} &:= 
        (\Lam{{f}}{\AbsBasis}{
                \LetP{x}{\B}{y}{\B}
                {(f (\Hd \ket{0}) (\Hd \ket{1}))}
                {\Pair{(\Hd x)}{y}}
        })\\
        \Hd &:= \Lam{x}{\B}{\case{x}{\ket{0}}{\ket{1}}{\ket{+}}{\ket{-}}}
    \end{align*}
    \caption{Deutsch algorithm term}
\end{table}

On \Cref{tab:Oracles} we note the four possible oracles. $D_1$ and $D_4$ correspond to the oracles encoding the 0 and 1 constant functions and $D_2$, $D_3$ to the identity and bit-flip respectively.

\begin{table}
    \scriptsize
    \begin{align*}
        D_1 :=& \Lam{x}{\B}{\Lam{y}{\B}{\Pair{x}{y}}}\\
        D_2 :=& \Lam{x}{\B}{\Lam{y}{\B}{\cnot{x}{y}}}\\
        D_3 :=& \Lam{x}{\B}{\Lam{y}{\B}{\cnot{x}{(\pauliX{y})}}}\\
        D_4 :=& \Lam{x}{\B}{\Lam{y}{\B}{\Pair{x}{(\pauliX{y})}}}\\
        \text{Where:} &\\
        \cnot{}{} :=& \Lam{x}{\B}{\Lam{y}{\B}{
        \case{x}
        {\ket{0}}{\ket{1}}
        {\Pair{\ket{0}}{y}}{\Pair{\ket{1}}{\pauliX{y}}}}}\\
        \pauliX{} :=& \Lam{x}{\B}{\case{x}{\ket{0}}{\ket{1}}{\ket{1}}{\ket{0}}}
    \end{align*}
    
    \caption{Oracles implementing the four possible functions $f:\{0,1\}\mapsto\{0,1\}$}
    \label{tab:Oracles}
\end{table}

Each of these oracles can be typed as $\B\Arr\B\Arr(\B\times\B)$. But since we are passing $\ket{+}$ and $\ket{-}$ as arguments, the typing we would be able to assign is: $\sharp\B\Arr\sharp\B\Arr\sharp(\B\times\B)$. Which means that the final typing for $\mathsf{Deutsch}$ would be:
\[
\TYP{}{\mathsf{Deutsch}}{(\sharp\B\Arr\sharp\B\Arr(\sharp\B\Arr\sharp\B))\Arr\sharp(\B\times\B)}
\]
This would seem to suggest that the result of the computation is a superposition of pairs of booleans.

However, this approach underutilizes the amount of information we have available. We know that the oracle will receive specifically the state $\ket{+-}$, and so we can rewrite the intervening terms taking this information into account. In \Cref{tab:DeutschShift} we restate the terms, but this time the abstractions and conditional cases are written in the basis $\XB=\{\ket{+},\ket{-}\}$.

\begin{table}
    \footnotesize
    \[
    \begin{array}{r c l}
        \mathsf{Deutsch}&:=~&(\Lam{{U_f}}{\AbsBasis}{
                \LetP{x}{\XB}{y}{\XB}
                {(U_f \ket{+} \ket{-})}
                {\\ && \case{x}{\ket{+}}{\ket{-}}{\ket{0}}{\ket{1}}}})\\
        D_1 &:= &\Lam{x}{\XB}{\Lam{y}{\XB}{\Pair{x}{y}}}\\
        D_2 &:= &\Lam{x}{\XB}{\Lam{y}{\XB}{\cnotXB{x}{y}}}\\
        D_3 &:= &\Lam{x}{\XB}{\Lam{y}{\XB}{\cnotXB{x}{(\pauliXXB{y})}}}\\
        D_4 &:= &\Lam{x}{\XB}{\Lam{y}{\XB}{\Pair{x}{(\pauliXXB{y})}}}\\
        \multicolumn{3}{l}{\text{Where:}}\\
        \cnotXB{}{} &:=& \Lam{x}{\XB}{\Lam{y}{\XB}{
        \case{y}
        {\\ && \ket{+}}{\\ && \ket{-}}
        {\Pair{x}{\ket{+}}}{\Pair{\pauliZXB{x}}{\ket{-}} \\ &&}}}\\
        \pauliZXB{} &:=& \Lam{x}{\XB}{\case{x}{\ket{+}}{\ket{-}}{\ket{-}}{\ket{+}}}\\
        \pauliXXB{} &:=& \Lam{x}{\XB}{\case{x}{\ket{+}}{\ket{-}}{\ket{+}}{(-1)\ket{-}}}\\
    \end{array}
    \]
    \caption{Deutsch term and oracles in the shifted Hadamard basis.}
    \label{tab:DeutschShift}
\end{table}

In this case, for each of the oracles we can assign the type $\XB\Arr\XB\Arr\XB\times\XB$ and type the term $\mathsf{Deutsch}$ as $(\XB\Arr\XB\Arr\XB\times\XB)\Arr\B$. There is a key difference here, the type of the oracles ensure that the result will be in the basis state $\XB\times\XB$. In other words, the result will be a pair with either $\ket{+}$ or $\ket{-}$ in its components (up to a global phase). Since we know this fact, we can manipulate the result of $f$ as we would with classical bits, and discard the second component. 

Both functions are equivalent on an operational point of view. But reframing it onto a different basis, allows us to give a more tight typing to the terms and more insight on how the algorithm works. If we analize the typing judgements, we observe that none of the variables has a $\sharp$ type. This has two consequences, first we can safely discard the second qubit and second, the Hadamard transform guarantees that the first qubit will yield a boolean. This correlates with the fact that Deutsch's algorithm is deterministic and we can statically ensure the result will be a basis vector.

\subsection{Quantum teleportation}\label{sec:teleportation}

The \emph{principle of deferred measurement} is a result which states that any quantum circuit can delay the measurements performed without modifying its outcome. More precisely, any gate controlled by the outcome of a measurement is equivalent to another gate whose control has not yet been measured. The calculus $\lambdaB$ does not implement a mechanism to measure states, but using the $\mathsf{case}$ constructor is possible to simulate these quantum controlled gates.

A notable example of an algorithm which makes use of classical controlled gates is the \emph{quantum teleportation}. In it, two agents (usually called Alice and Bob) share two parts of a Bell state and make use of the entanglement to move a quantum state from a qubit owned by Alice to a qubit owned by Bob. The quantum circuit representation of the algorithm is the following:

\begin{align*}
    \Qcircuit @C=1em @R=.7em {
     \lstick{\ket{\phi}} & \qw & \qw & \ctrl{1} & \gate{H} & \meter & \control \cw \\
     \lstick{\ket{0}} & \qw & \targ & \targ & \meter & \control \cw \cwx[1] \\
     \lstick{\ket{0}} & \gate{H} & \ctrl{-1} & \qw & \qw & \targ & \gate{Z} \cwx[-2] \qw & \rstick{\ket{\phi}} \qw
    }
\end{align*}

The algorithm first encodes the Bell state $\Phi^+$ onto the second and third qubit and then performs a Bell basis measurement on the first and second qubit. In order to do this, it first decomposes applying a CNOT gate followed by a Hadamard gate on the first qubit (the adjoint of the Bell state generation). Then the first and second qubit are measured, which informs the correction needed for the third qubit to recover the state $\phi$.

We can simulate the operation of the algorithm, via a $\lambda$-term which instead of outright measuring, describes the steps to take in each of the possible outcomes. A possible implementation is:

\begin{align*}
    (\Lam{x}{\B}{\LetP{y_1}{\B}{y_2}{\B}{\Phi^+}{ ~\mathsf{case } \Pair{x}{y_1}  ~\mathsf{ of }~\{ &\Phi^+\mapsto \Pair{\Phi^+}{y_2}\\
    &\Phi^-\mapsto \Pair{\Phi^-}{Z y_2}\\
    &\Psi^+\mapsto \Pair{\Psi^+}{X y_2}\\
    &\Psi^-\mapsto \Pair{\Psi^-}{ZX y_2}\\
    &\}}})
\end{align*}

The $\lambda$-term takes the state $\ket{\phi}$ as an argument, then matches the first qubit of the Bell pair and the $\ket{\phi}$ qubit, with the vectors of the Bell basis. In each branch, corrects the third qubit to recover the original $\ket{\phi}$ state. This is akin to controlling the correction with each of the Bell basis vectors.

The $\lambdaB$ calculus provides syntax which allows the abstraction of the steps encoding and decoding on the Bell basis. This technique makes full use of the deferred measurement principle and can be applied to measurements on arbitrary bases. The final type of the term is $\sharp\basis{\B}\Arr \sharp\basis{\Bell}\times \sharp\basis{\B}$.

{\color{red} TODO: HABLAR DEL PAPER DE SIMON ACÃ EN UNA NUEVA SUBSECTION}

\section{Conclusion}\label{sec:conclusion}

% Introduction
In this chapter we explore a quantum-data/quantum-control $\lambda$-calculus, with the additional feature of framing the abstraction in different bases besides the canonical one.

% Syntax & substitutions
The mechanism needed to implement this idea is the decoration in $\lambda$-terms and $\mathsf{let}$ constructors. Along with a new substitution which dictates the decomposition of the value distribution onto different bases. These changes do not add expressive power to the original calculus it is based from, however they provide a different point of view when writing programs. 

% Reduction system
The reduction system itself orchestrates the computation and makes use of the syntax and substitution previously defined. The main point to note is that the evaluation commutes with the congruence relationship, ensuring that interpreting a vector in a different basis does not alter the result of the computation. And in turn, allows us to consider value distributions modulo this congruence.

% Realizability model
The previous work pays its dividends when considering the realizability model. The inclusion of the atomic types $\basis{X}$, is used to characterise the abstractions that represent unitary functions. This is the main result of the section and is a generalisation of the characterisation found in \cite{DiazcaroGuillermoMiquelValironLICS19}. Here, the use of basis types gives way to a simpler proof. 

% Typing system
The other main result of the chapter is the validity of the several typing rules described in \Cref{tab:TypingRules}. Extracting them via the realizability technique, ensures their correctness and can later form the foundation of the type system for a programming language.

% Examples
Finally, we present two examples that showcase the advantage of the typing system and syntax. First Deutsch's algorithm, which exhibits a more expressive type and in turn, allows to treat the result classically. Second, the case for quantum teleportation, where we are able to simulate gates controlled by a Bell basis measurement as branches on a pattern matching $\mathsf{case}$. 

% Things left to do
There are a few remaining lines of research that stem from this work. A natural progression would be to provide a categorical model to study the calculus through a different lens and relate it to other well studied systems. 

As well, we could try to give a translation into an intermediate language like ZX alongside the lines of the second chapter. Proving that, despite the programs being detached from the circuitry, they can still be  implemented concretely.

% En la parte de conclusiones/trabajo futuro, me gustarÃ­a meter otra nociÃ³n de producto interno que juegue bien con las funciones. Con esta definiciÃ³n una funciÃ³n es ortogonal a su eta expansiÃ³n. O (\x. t_1 + t_2) _|_ (\x. t_2 + t_1)


%\begin{credits}
%\subsubsection{\ackname} 
%Supported by the European Union through the MSCA SE project QCOMICAL (Grant Agreement ID: 101182521) 
%the Plan France 2030 through the PEPR integrated project EPiQ (ANR-21-PETQ-0007),
%and by the Uruguayan CSIC grant 22520220100073UD.
%
%\subsubsection{\discintname}
%The authors have no competing interests to declare that are
%relevant to the content of this article.
%\end{credits}
%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
\bibliographystyle{splncs04}
\bibliography{basisSensitive}

\clearpage

\makeatletter
\renewcommand*\theHsection{\thesection}
\makeatother
\appendix

\section{Omitted proofs from Section~\ref{sec:calculus}}\label{sec:appendixA}

\begin{restatetheorem}[Restatement of \Cref{thm:UniqueDecomposition}]
  \itshape
  If $B$ is an $n$-dimensional basis, then every $n$-dimensional qubit has
  a unique decomposition over $B$.
\end{restatetheorem}
\begin{proof}
  Let $\vv{b_i}$ be the basis vectors of $B$. Suppose
  $\sum_{i=1}^n \alpha_i \vv{b_i}$ and $\sum_{i=1}^n \beta_i \vv{b_i}$
  are two decompositions of $\vv{v}$ over $B$. Then
  \[
    0=\vv{v}-\vv{v}=\sum_{i=1}^{n}(\alpha_i-\beta_i)\vv{b_i}.
  \]
  By linear independence, $\alpha_i=\beta_i$ for all $i$.
\end{proof}

\begin{restatecorollary}[Restatement of \Cref{cor:EquivalentDecomposition}]
  \itshape
  If $\vv{v}\equiv\vv{w}$, then they share the same decomposition over any
  basis $B$.
\end{restatecorollary}
\begin{proof}
  Since $\vv{v}-\vv{w}\equiv\vv{v}-\vv{v}\equiv\vv{w}-\vv{w}$, the same
  argument as in \Cref{thm:UniqueDecomposition} shows that $\vv{v}$ and $\vv{w}$ have the
  same decomposition over $B$.
\end{proof}

\begin{restatelemma}[Restatement of \Cref{lem:distributiveSubstitution}]
  \itshape
  For term distributions $\vv{t_i}$, a value distribution $\vv{v}$, a
  variable $x$, coefficients $\alpha_i\in\C$, and a basis $B$ such that
  $\ansubst{\vv v/x}{B}$ is defined:
  \[
    \Bigl(\sum_i \alpha_i\vv{t_i}\Bigr)\ansubst{\vv v/x}{B}
    \equiv
    \sum_i \alpha_i\vv{t_i} \ansubst{\vv v/x}{B}.
  \]
\end{restatelemma}
\begin{proof}
  Let $B\neq\AbsBasis$ and
  $\vv{v}\equiv\sum_{j=1}^n\beta_j\vv{b_j}$ with each $\vv{b_j}\in B$.
  Then
  \begin{align*}
    \Bigl(\sum_i \alpha_i\vv{t_i}\Bigr)\ansubst{\vv v/x}{B}
    &= \sum_{j=1}^n \beta_j\Bigl(\sum_{i=1}^{n}\alpha_i t_i\Bigr)[\vv{b_j}/x]\\
    &\equiv \sum_{i=1}^{n}\alpha_i\Bigl(\sum_{j=1}^n\beta_j t_i[\vv{b_j}/x]\Bigr)
    = \sum_{i=1}^{n}\alpha_i\vv{t_i}\ansubst{\vv v/x}{B}.
  \end{align*}
  The case $B=\AbsBasis$ is analogous.
\end{proof}

\begin{restatelemma}[Restatement of \Cref{lem:EquivSubstitutions}]
  \itshape
  For value distributions $\vv{v},\vv{w}$, a term distribution $\vv{t}$, and
  an orthonormal basis $B$ such that both
  $\ansubst{\vv{v}/x}{B}$ and $\ansubst{\vv{w}/x}{B}$ are defined:
  if $\vv{v}\equiv\vv{w}$, then
  $\vv{t}\ansubst{\vv{v}/x}{B}
  =\vv{t}\ansubst{\vv{w}/x}{B}$.
\end{restatelemma}
\begin{proof}
  Since $\vv{v}\equiv\vv{w}$, by
  \Cref{cor:EquivalentDecomposition},
  both can be written as
  $\vv{v}\equiv\vv{w}\equiv\sum_{i=1}^{n}\alpha_i\vv{b_i}$ with
  $\vv{b_i}\in B$. Hence
  \[
    \vv{t}\ansubst{\vv{v}/x}{B}
    = \sum_{i=1}^{n}\alpha_i\vv{t}[\vv{b_i}/x]
    = \vv{t}\ansubst{\vv{w}/x}{B}.
  \]
\end{proof}

\section{Omitted proofs from Section~\ref{sec:reduction}}\label{sec:appendixB}

\begin{lemma}[Weak diamond property for $\lraneq$]\label{lem:SquigDiamond}
  Let $\vv{t}, \vv{s_1}, \vv{s_2}$ term distributions such that $\vv{t}\lraneq{s_1}$ and $\vv{t}\lraneq\vv{s_2}$. Then, either there exists a term distribution $\vv{r}$ such that $\vv{s_1}\lraneq\vv{r}$ and $\vv{s_2}\lraneq \vv{r}$. Or, $\vv{s_1}=\vv{s_2}$. Diagrammatically:
  \[
    \begin{tikzcd}
      & \vv{t}
        \arrow[ld,decorate,decoration={snake, amplitude=0.8, segment length=6pt}, ->]
        \arrow[rd,decorate,decoration={snake, amplitude=0.8, segment length=6pt}, ->]
      &\\
      \vv{s_1}\arrow[dr,dashed,decorate,decoration={snake, amplitude=0.8, segment length=6pt}, ->] & &
      \vv{s_2}\arrow[ld,dashed,decorate,decoration={snake, amplitude=0.8, segment length=6pt}, ->] \\
      & \vv{r} &
    \end{tikzcd}
    \quad\text{ Or }\quad
    \begin{tikzcd}
      &[-2em] \vv{t}
        \arrow[ld,decorate,decoration={snake, amplitude=0.8, segment length=6pt}, ->]
        \arrow[rd,decorate,decoration={snake, amplitude=0.8, segment length=6pt}, ->]
      &[-2em]\\
      \vv{s_1}& = &\vv{s_2}\\
    \end{tikzcd}
  \]
\end{lemma}

\begin{proof}
  The proof follows from the fact that the $\lraneq$ reduction is deterministic over pure values. And, in case of term distributions, we only need to match the reduction on the corresponding sub-terms. Let $\vv{t}=\sum\limits_{i=1}^n \alpha_i \vv{t_i}$, $\vv{s_1}=\sum\limits_{i=1; i\neq j}^n \alpha_i \vv{t_i} + \alpha_j\vv{s_j}$, and $\vv{s_2}=\sum\limits_{i=1; i\neq k}^n \alpha_i \vv{t_i}+\alpha_k\vv{s_k}$. Where $\vv{t_j}\lraneq\vv{s_j}$ and $\vv{t_k}\lraneq\vv{s_k}$. If $j=k$ we are done, so we consider the case where $j\neq k$. Diagrammatically:
  \[
    \begin{tikzcd}
      &[-1em] \sum\limits_{i=1}^n \alpha_i \vv{t_i}
        \arrow[ld,decorate,decoration={snake, amplitude=0.8, segment length=6pt}, ->]
        \arrow[rd,decorate,decoration={snake, amplitude=0.8, segment length=6pt}, ->]
      &[-1em]\\
      \sum\limits_{i=1; i\neq j}^n \alpha_i \vv{t_i} + \alpha_j\vv{s_j}
      \arrow[dr,dashed,decorate,decoration={snake, amplitude=0.8, segment length=6pt}, ->] & &
      \sum\limits_{i=1; i\neq k}^n \alpha_i \vv{t_i} + \alpha_k\vv{s_k}
      \arrow[ld,dashed,decorate,decoration={snake, amplitude=0.8, segment length=6pt}, ->] \\
      & \sum\limits_{i=1; i\neq j,k}^n \alpha_i \vv{t_i} + \alpha_j\vv{s_j}+\alpha_k\vv{s_k} &
    \end{tikzcd}
  \]
\end{proof}

\begin{restatetheorem}[Restatement of \Cref{thm:confluence}]
  \itshape
  Let $\vv{t}$ and $\vv{s}$ be closed term distributions with
  $\vv{t}\equiv\vv{s}$. If $\vv{t}\lraneq\vv{t'}$ and $\vv{s}\lraneq\vv{s'}$,
  then there exist term distributions $\vv{r_1}$ and $\vv{r_2}$ such that
  $\vv{t'}\eval\vv{r_1}$, $\vv{s'}\eval\vv{r_2}$, and
  $\vv{r_1}\equiv\vv{r_2}$.
  Diagrammatically:
  \[
    \begin{tikzcd}
      & \vv{t}
        \arrow[ld,decorate,decoration={snake, amplitude=0.8, segment length=6pt}, ->]
        &[-2.5em] \equiv
        &[-2.5em] \vv{s}
        \arrow[rd,decorate,decoration={snake, amplitude=0.8, segment length=6pt}, ->]
        &\\
      \vv{t'}\arrow[dr,"*",pos=0.9] & & & &
      \vv{s'}\arrow[ld,"*"',pos=0.9] \\
      & \vv{r_1} & \equiv & \vv{r_2} &
    \end{tikzcd}
  \]
\end{restatetheorem}
\begin{proof}
  We do a case-by-case analysis over the relation $\vv{t}\equiv\vv{s}$.
  \begin{description}
    \item[$\vv{t_1} + 0\vv{t_2}\equiv\vv{t_1}$:] This case follows from Lemma \ref{lem:SquigDiamond} since the reductions can only be performed in $\vv{t_1}$.
    
    \item[$0\vv{t}\equiv\vv{0}$:] The term distributions cannot reduce on either side of the equivalence.
    
    \item[$1\vv{t}\equiv\vv{t}$:] This case follows from Lemma \ref{lem:SquigDiamond}.
    
    \item[$\alpha(\beta \vv{t})\equiv\delta\vv{t}$:] This case follows from Lemma \ref{lem:SquigDiamond}.
    
    \item[$\vv{t_1}+\vv{t_2}\equiv\vv{t_2}+\vv{t_1}$:] This case follows from Lemma \ref{lem:SquigDiamond}. We just have to match the reductions on both sides of the equivalence.
    
    \item[$\vv{t_1}+(\vv{t_2}+\vv{t_3})\equiv(\vv{t_1}+\vv{t_2})+\vv{t_3}$:] This case follows from Lemma \ref{lem:SquigDiamond}. We just have to match the reductions on both sides of the equivalence.
    
    \item[$(\alpha+\beta)\vv{t}\equiv\vv{t}$:] We start analyzing the coefficients. If $\alpha+\beta = 0$, then there cannot be a reduction on the left hand-side. If $(\alpha + \beta)\neq 0$ and either $\alpha=0$ or $\beta=0$, then we are on a particular case of $\vv{t_1} + 0\vv{t_2}\equiv\vv{t_1}$ with $\vv{t_1}=\vv{t_2}$. Otherwise, we match the reductions on both sides of the equivalence with Lemma \ref{lem:SquigDiamond}.
    
    \item[$\alpha(\vv{t_1}+\vv{t_2})\equiv\alpha\vv{t_1}+\alpha\vv{t_2}$:] If $\alpha=0$, then the term distributions cannot reduce on either side of the equivalence. Otherwise, we match the reductions on both sides of the equivalence with Lemma \ref{lem:SquigDiamond}.
    
    \item[$\vv{t} (\alpha\vv{s})\equiv\alpha(\vv{t}\vv{s})$:] If $\alpha=0$, then there is no reduction possible on the right-hand side. If there is an internal reduction on either $\vv{s}$ or $\vv{t}$, then we match the reductions on both sides of the equivalence with Lemma \ref{lem:SquigDiamond}.
    
    If $\vv{t} = (\Lam{x}{B}{\vv{t_1}})$ and $\vv{s}=\vv{v}$ and $\vv{t_1}\ansubst{\vv{v}}{B}$, is defined then (we consider the case $B\neq\AbsBasis$):
    \begin{align*}
      (\Lam{x}{B}{\vv{t_i}}) (\alpha\vv{v}) &\lraneq \vv{t_1}\ansubst{\alpha\vv{v}/x}{B}\\
      &= \sum_{i=1}^{n} \alpha\beta_i \vv{t_1}[\vv{b_i}/x]\quad \text{with }\vv{v}\equiv\sum_{i=1}^{n} \beta_i \vv{b_i} \text{ with } \vv{b_i}\in B\\
    \end{align*}
    On the other side:
    \begin{align*}
      \alpha ((\Lam{x}{B}{\vv{t_1}}) \vv{v}) &\lraneq \alpha(\vv{t_1\ansubst{\vv{v}}{B}})\\
      &=\alpha(\sum_{i=1}^{n} \beta_i \vv{t_1}[\vv{b_i}/x])\quad \text{with }\vv{v}\equiv\sum_{i=1}^{n} \beta_i \vv{b_i} \text{ with } \vv{b_i}\in B\\
    \end{align*}

    And we have that both terms are equivalent. The case for $B=\AbsBasis$ is similar.
    
  \end{description}
\end{proof}

\section{Omitted proofs from Section~\ref{sec:model}}\label{sec:appendixC}

\begin{restatetheorem}[Restatement of \Cref{thm:SharpCharacterization}]
  \itshape
  The interpretation of a type~$\sharp A$ contains precisely the
  norm-$1$ linear combinations of values in~$\sem{A}$:
  \[
    \sem{\sharp A}
    = (\sem{A}^\bot)^\bot
    = \Span(\sem{A}) \cap \Sph.
  \]
\end{restatetheorem}
\begin{proof}
  Proof by double inclusion.
  \begin{description}
    \item[$\Span(\sem{A})\cap\Sph\subseteq (\sem{A}^\bot)^\bot$:] Let $\vv{v}\in\Span(\sem{A})\cap\Sph$. Then $\vv{v}$ is of the form $\sum_{i=1}^{n}\alpha_i \vv{v_i}$ with $\vv{v_i}\in\sem{A}$. Taking $\vv{w}\in\sem{A}^\bot$, we examine the inner product:
    
    \begin{align*}
    \scal{\vv{v}}{\vv{w}} &= \scal{\sum_{i=1}^{n}\alpha_i \vv{v_i}}{\vv{w}}\\
    &= \sum_{i=1}^{n}\overline{\alpha_i}\scal{\vv{v_i}}{\vv{w}}=0
    \end{align*}

    Then $\vv{v}\in(\sem{A}^\bot)^\bot$.

    \item[$(\sem{A}^\bot)^\bot\subseteq \Span(\sem{A})\cap\Sph$:] Reasoning by contradiction, we assume that there is a $\vv{v}\in(\sem{A}^\bot)^\bot$ such that $v\not\in\Span(\sem{A})\cap\Sph$. Since $\vv{v}\not\in\Span(\sem{A})$, $\vv{v}=\vv{w_1} + \vv{w_2}$ such that $\vv{w_1}\in\Span{\sem{A}}$ and $\vv{w_2}$ is a non-null vector which cannot be written as a linear combination of elements of $\sem{A}$. In other words, $\vv{w_2}\in\sem{A}^\bot$. Taking the inner product:
    \[
    \scal{\vv{v}}{\vv{w_2}} = \scal{\vv{w_1}+\vv{w_2}}{\vv{w_2}} = \|\vv{w_2}\|\neq 0
    \]
    Then $\vv{v}\not\in(\sem{A}^\bot)^\bot$. The contradiction stems from assuming $\vv{v}\not\in\Span{\sem{A}}\cap\Sph$.\qedhere
  \end{description}
\end{proof}

\begin{restatetheorem}[Restatement of \Cref{thm:IdempotentSharp}]
  \itshape
  The~$\sharp$ operator is idempotent; that is,
  $\sem{\sharp A} = \sem{\sharp(\sharp A)}$.
\end{restatetheorem}
\begin{proof}
  We want to prove that $(((\comp{\sem{A}})^\bot)^\bot)^\bot = (\comp{\sem{A}})^\bot$. For ease of reading, we will write $\comp[n]{A}$ for $n$ successive applications of the operation $\bot$.

  \begin{description}
    \item[$A\subseteq A^{\bot^2}$:] Let $\vv{v}\in A$. Then, for all $\vv{w}\in\comp{A}$, $\scal{\vv{v}}{\vv{w}} = 0$. Then $\vv{v}\in\comp[2]{A}$. With this we have $A\subseteq\comp[2]{A}$.
    
    \item[$A^{\bot^3}\subseteq \comp{A}$:] Let $\vv{u}\in \comp[3]{A}$. Then, for all $\vv{v}\in\comp[2]{A}$, $\scal{\vv u}{\vv v} = 0$. Since we have shown that $A\subseteq \comp[2]{A}$, we have that for all $\vv{w}\in A$, $\scal{\vv u}{\vv w} = 0$. Then $\vv u\in\comp{A}$. With this we have $\comp[3]{A}\subseteq \comp{A}$.
  \end{description}

  With these two inclusions we have that $\comp{A}=\comp[3]{A}$. So we conclude that: $\sem{\sharp(\sharp A)} = \comp[4]{A} = \comp[2]{A} = \sem{\sharp A}$ \qedhere
\end{proof}

\begin{restatetheorem}[Restatement of \Cref{prop:UnitaryTypes}]
  \itshape
  For every type~$A$, $\sem{A}\subseteq\Sph$.
\end{restatetheorem}

\begin{proof}
  Proof by induction on the shape of $A$. Since by definition, $\sem{\basis{X}}$, $\sem{A\Arr B}$ and $\sem{\sharp{A}}$ are built from values in $\Sph$ the only case we need to examine is $\sem{A\times B}$.
  
  Let $\vv v = \sum_{i=0}^{n} \alpha_i v_i \in\sem{A}$ and $\vv w = \sum_{j=0}^{m} \beta_j w_j$ where every $v_i$ are pairwise orthogonal, same for $w_j$. Then:
     
  \[(\vv v, \vv w) = \sum_{i=0}^{n} \sum_{j=0}^{m} \alpha_i\beta_j (v_i,w_j)\]
  
  So we have: 
  \[\|\Pair{\vv v}{\vv w}\| = \sqrt{\sum_{i=1}^n\sum_{j=1}^{m} |\alpha_i\beta_j|^2} = \sqrt{\sum_{i=1}^n |\alpha_i|^2 \sum_{j=1}^{m} |\beta_j|^2}\]

  Since both $\vv v\in\sem{A}$ and $\vv w\in\sem{B}$, by inductive hypothesis, we have that $\|\vv v\| = \| \vv w \| = 1$. Which is to say $\sum_{i=1}^{n} |\alpha_i|^2 = \sum_{j=1}^{m} |\beta_j| = 1$. So we conclude $\|\Pair{\vv{v}}{\vv{w}}\| = 1$.
  \qed
\end{proof}

\begin{restatelemma}[Restatement of \Cref{lem:BasesIso}]
  Let $X$ and $Y$ be orthonormal bases of the same finite
  dimension, and let $\Lam{x}{X}{\vv t}$ be a closed $\lambda$-abstraction.
  Then $\Lam{x}{X}{\vv t}\in\sem{\sharp\basis{X}\Arr\sharp\basis{Y}}$
  if and only if 
  for all $\vv{v_i},\vv{v_j}\in\sem{\basis{X}}$,
  there exist value distributions
  $\vv{w_i},\vv{w_j}\in\sem{\sharp\basis{Y}}$ such that,
  \[
    \vv{t}[\vv{v_i}/x]\eval\vv{w_i}
    \quad\text{and}\quad
    \vv{t}[\vv{v_j}/x]\eval\vv{w_j},
    \quad\text{with } 
    \vv{w_i}\perp\vv{w_j}\text{ whenever }i\neq j.
  \]
\end{restatelemma}
\begin{proof}
  \textit{The condition is necessary:} Suppose that $\Lam{x}{X}{\vv{t_k}}\in\sem{\sharp\basis{X}\Arr\sharp\basis{Y}}$, thus $\forall \vv{v_i}\in\sem{\sharp\basis{X}},\ \vv{t}\ansubst{\vv{v_i}/x}{X}\eval\vv{w_i}\in\sem{\sharp\basis{Y}}$. It remains to be seen that $\vv{w_i} \perp \vv{w_j}$ if $i\neq j$. For that, we consider $\alpha_i\in\C$ such that $\sum_{i=1}^n |\alpha_i|^2 = 1$. By linear application on the basis $X$ we observe that:
  \begin{align*}
    (\Lam{x}{X}{\vv{t}})(\sum_{i=1}^n \alpha_i \vv{v_i}) &\lra \vv t\ansubst{\sum_{i=1}^n \alpha_i \vv{v_i}/x}{X}
    = \sum_{i=1}^{n} \alpha_i \vv{t}[\vv{v_i}/x] 
    \eval \sum_{i=1}^n \alpha_i \vv{w_i}
  \end{align*}

  But since $\sum_{i=1}^n \alpha_i \vv{v_i}\in\sem{\sharp A}$, then $\sum_{i=1}^n \alpha_i \vv{w_i}\in\sem{\sharp B}$ too. Which implies $\|\sum_{i=1}^n \alpha_i \vv{w_i}\|=1$. Therefore:
  \begin{align*}
    1 = \|\sum_{i=1}^n \alpha_i \vv{w_i}\| &= \scal{\sum_{i=1}^n \alpha_i \vv{w_i}}{\sum_{j=1}^n \alpha_j \vv{w_j}}\\
    &=\sum_{i=1}^n |\alpha_i|^2 \scal{\vv{w_i}}{\vv{w_i} } + \sum_{i,j=1; i\neq j}^n \bar{\alpha_i}\alpha_j \scal{\vv{w_i}}{\vv{w_j}}\\
    &=\sum_{i=1}^n |\alpha_i|^2 \scal{\vv{w_i}}{\vv{w_i} } + \sum_{i,j=1; i<j}^n 2~\Rpart{\bar{\alpha_i}\alpha_j \scal{\vv{w_i}}{\vv{w_j}}}\\
    &=\sum_{i=1}^n |\alpha_i|^2 \|\vv{w_i}\|^2 + 2\sum_{i,j=1; i<j}^n \Rpart{\bar{\alpha_i}\alpha_j \scal{\vv{w_i}}{\vv{w_j}}}\\
    &=\sum_{i=1}^n |\alpha_i|^2 + 2\sum_{i,j=1; i<j}^n\Rpart{\bar{\alpha_i}\alpha_j \scal{\vv{w_i}}{\vv{w_j}}}\\
    &= 1 + 2\sum_{i,j=1; i<j}^n \Rpart{\bar{\alpha_i}\alpha_j \scal{\vv{w_i}}{\vv{w_j}}}
  \end{align*}

  And thus we are left with $\sum_{i,j=1; i<j}^n \Rpart{\bar{\alpha_i}\alpha_j \scal{\vv{w_i}}{\vv{w_j}}} = 0$. Taking $\alpha_{i'} = \alpha_{j'} = \frac{1}{\sqrt{2}}$ with $0$ for the rest of coefficients, we have $\Rpart{\scal{\vv{w_{i'}}}{\vv{w_{j'}}}} = 0$ for any two arbitrary $i'$ and $j'$. In the same way, taking $\alpha_{i'} = \frac{1}{\sqrt{2}}$ and $\alpha_{j'}=\frac{i}{\sqrt{2}}$ with $0$ for the rest of the coefficients, we have $\Ipart{\scal{\vv{w_{i'}}}{\vv{w_{j'}}}} = 0$ for any two arbitrary $i'$ and $j'$. Finally, we can conclude that $\scal{\vv{w_i}}{\vv{w_j}}=0$ if $i\neq j$.

  \textit{The condition is sufficient:} Suppose that there are $\vv{w_i}\in\sem{\sharp\basis{Y}}$ such that for every $\vv{v_i}\in\sem{\basis{X}}$:
  \[
    \vv t[\vv{v_i}/x] \eval \vv{w_i} \perp \vv{w_j} \lave \vv t[\vv{v_j}/x]\qquad \text{If } i\neq j
  \]
  Given any $\vv u\in\sem{\sharp\basis{X}}$ we have that $\vv u = \sum_{i=1}^n \alpha_i \vv{v_i}$ with $\sum_{i=1}^n |\alpha_i|^2 = 1$ and $\vv{v_i}\in\sem{\basis{X}}$. Then 
  \[
    (\Lam{x}{X}{\vv t}) \vv u \lra \vv{t_k}\ansubst{\vv u/x}{X}=\sum_{i=1}^{n}\alpha_i \vv{t}[\vv{v_i}/x]\eval\sum_{i=1}^n \alpha_i\vv{w_i}
  \]

  We have that for each $i$, $\vv{w_i}\in\sem{\sharp\basis{Y}}$. In order to show that $(\Lam{x}{A}{\vv t})\vv u\real\sharp\basis{Y}$ we still have to prove that $\|\sum_{i=1}^n \alpha_i \vv{w_i}\| = 1$

  \begin{align*}
    \|\sum_{i=1}^n \alpha_i \vv{w_i}\|^2 &= \scal{\sum_{i=1}^n \alpha_i \vv{w_i}}{\sum_{j=1}^n \alpha_j \vv{w_j}}\\
    &=\sum_{i=1}^n |\alpha_i|^2 \scal{\vv{w_i}}{\vv{w_i} } + \sum_{i,j=1; i\neq j}^n \bar{\alpha_i}\alpha_j \scal{\vv{w_i}}{\vv{w_j}}\\
    &=\sum_{i=1}^n |\alpha_i|^2 + 0\\
    &= 1
  \end{align*}

  Then $\sum_{i=1}^n \alpha_i \vv{w_i}\in\sem{\sharp(\sharp\basis{Y})}=\sem{\sharp\basis{Y}}$ by \Cref{thm:IdempotentSharp}. Since for every $\vv u\in\sem{\sharp A}$, $(\Lam{x}{A}{\vv t}) \vv u\real\sharp B$, we can conclude that $\Lam{x}{A}{\vv t}\in\sem{\sharp A\Arr\sharp B}$.\qedhere
\end{proof}

\section{A Proofs for validity of LetT}

\begin{theorem}\label{prop:InnerProdPairs} For all value distributions $\vv{v_1}, \vv{v_2}, \vv{w_1}, \vv{w_2}$ we have:
\[
\scal{\Pair{\vv{v_1}}{\vv{w_1}}}{\Pair{\vv{v_2}}{\vv{w_2}}} = \scal{\vv{v_1}}{\vv{v_2}}\scal{\vv{w_1}}{\vv{w_2}}
\]
\begin{proof}
    Let us write $\vv{v_1}=\sum_{i_1=1}^{n_1}\alpha_{i_1} v_{i_1}$, $\vv{v_2}=\sum_{i_2=1}^{n_2}\alpha'_{i_2} v_{i_2}$, $\vv{w_1}=\sum_{j_1=1}^{m_1}\beta_{j_1} w_{j_1}$ and $\vv{w_2}=\sum_{j_2=1}^{m_2}\beta'_{j_2} w_{j_2}$. Then we have:
    \begin{align*}
        &\scal{\Pair{\vv{v_1}}{\vv{w_1}}}{\Pair{\vv{v_2}}{\vv{w_2}}}\\
        &=\scal{\sum_{i_1=1}^{n_1}\sum_{j_1=1}^{m_1} \alpha_{i_1}\beta'_{j_1}\Pair{v_{i_1}}{w_{j_1}}}{\sum_{i_2=1}^{n_2}\sum_{j_2=1}^{m_2} \alpha_{i_2}\beta'_{j_2}\Pair{v_{i_2}}{w_{j_2}}}\\
        &=\sum_{i_1}^{n_1}\sum_{j_1}^{m_1}\sum_{i_2}^{n_2}\sum_{j_2}^{m_2} \overline{\alpha_{i_1}\beta_{j_1}} \alpha'_{i_2}\beta'_{j_2} \scal{\Pair{v_{i_1}}{w_{j_1}}}{\Pair{v_{i_2}}{w_{j_2}}}\\
        &=\sum_{i_1}^{n_1}\sum_{j_1}^{m_1}\sum_{i_2}^{n_2}\sum_{j_2}^{m_2} \overline{\alpha_{i_1}\beta_{j_1}} \alpha'_{i_2}\beta'_{j_2} \Kron{\Pair{v_{i_1}}{w_{j_1}}}{\Pair{v_{i_2}}{w_{j_2}}}\\
        &=\sum_{i_1}^{n_1}\sum_{j_1}^{m_1}\sum_{i_2}^{n_2}\sum_{j_2}^{m_2} \overline{\alpha_{i_1}\beta_{j_1}} \alpha'_{i_2}\beta'_{j_2} \Kron{v_{i_1}}{v_{i_2}}\Kron{w_{j_1}}{w_{j_2}}\\
        &=(\sum_{i_1}^{n_1}\sum_{j_1}^{m_1}\overline{\alpha_{i_1}}\alpha'_{i_2}\Kron{v_{i_1}}{v_{i_2}})(\sum_{i_2}^{n_2}\sum_{j_2}^{m_2} \overline{\beta_{j_1}} \beta'_{j_2} \Kron{w_{j_1}}{w_{j_2}})\\
        &=(\sum_{i_1}^{n_1}\sum_{j_1}^{m_1}\overline{\alpha_{i_1}}\alpha'_{i_2}\Pair{v_{i_1}}{v_{i_2}})(\sum_{i_2}^{n_2}\sum_{j_2}^{m_2} \overline{\beta_{j_1}} \beta'_{j_2} \Pair{w_{j_1}}{w_{j_2}})\\
        &=\scal{\vv{v_1}}{\vv{v_2}}\scal{\vv{w_1}}{\vv{w_2}}\\
    \end{align*}
\end{proof}  

\end{theorem}

\begin{lemma}\label{lem:VecRewrite}%A5 en el paper de LICS
Given a type $A$, two vectors $\vv{u_1},\vv{u_2}\in\sem{\sharp A}$ and a scalar $\alpha\in\C$, there exists a vector $\vv{u_0}\in\sem{\sharp A}$ and a scalar $\lambda\in\C$ such that:
\[
\vv{u_1} + \alpha\vv{u_2} = \lambda \vv{u_0} 
\]
\end{lemma}
\begin{proof}
    Let $\lambda:=\|\vv{u_1}+\alpha\vv{u_2}\|$. When $\lambda\neq 0$, we take $\vv{u_0}=\frac{1}{\lambda}(\vv{u_1}+\alpha\vv{u_2})\in\sem{\sharp A}$, and we are done.

    When $\lambda=0$, we first observe that $\alpha\neq 0$ since it would mean that $\|\vv{u_1}\|=0$ which is absurd since $\|\vv{u_1}\|=1$. Moreover, since $\lambda=\|\vv{u_1}+\alpha\vv{u_2}\|=0$, we observe that all the coefficients of the distribution $\vv{u_1}+\alpha\vv{u_2}$ are zeroes when written in canonical form which implies that:
    \[
    \vv{u_1}+\alpha\vv{u_2} = 0(\vv{u_1}+\alpha\vv{u_2}) = 0\vv{u_1}+0\vv{u_2}
    \]
    Using the triangular inequality we observe that:
    \begin{align*}
    0 &< 2|\alpha|\\
    &= \|2\alpha\vv{u_2}\|\\
    &\leq\|\vv{u_1}+\alpha\vv{u_2}\| + \|\vv{u_1 }+ (-\alpha)\vv{u_2}\|\\
    &= \|\vv{u_1}+(-\alpha)\vv{u_2}\|
    \end{align*}
    Hence $\lambda' := \|\vv{u_1}+(-\alpha)\vv{u_2}\|>0$. Taking $\vv{u_0}:= \frac{1}{\lambda'}(\vv{u_1}+ (-\alpha)\vv{u_2})\in\sem{\sharp A}$, we easily see that:
    \[
    \vv{u_1}+\alpha\vv{u_2} = 0\vv{u_1} + 0\vv{u_2} = 0(\frac{1}{\lambda'} (\vv{u_1} + (-\alpha) \vv{u_2})) = \lambda \vv{u_0}
    \]
\end{proof}

\begin{theorem}[Polarization identity]\label{prop:Polarization} %A6
For all values $\vv{v}$ and $\vv{w}$ we have:
\begin{align*}
&\scal{\vv{v}}{\vv{w}}=\\
&\frac{1}{4} (\|\vv{v}+\vv{w}\|^2 - \|\vv{v} + (-1) \vv{w}\|^2 - i\|\vv{v} + i\vv{w}\|^2 + i\|\vv{v}+ (-i)\vv{w}\|^2)
\end{align*}
\end{theorem}

\begin{lemma}\label{lem:InnerProdSingleVar} %A7
Given a valid typing judgement of the term $\TYP{\Delta,x_B:\sharp A}{\vv{s}}{C}$, a substitution $\sigma\in\sem{\Delta}$ and value distributions $\vv{u_1},\vv{u_2}\in\sem{\sharp A}$, there are value distributions $\vv{w_1}, \vv{w_2}\in\sem{C}$ such that:
\[
\begin{array}{c}
    \vv{s}\ansubst{\sigma}{}\ansubst{\vv{u_1}/x}{B_1}{\ansubst{\vv{v_1}/y}{B_2}}\eval\vv{w_1}\\
    \vv{s}\ansubst{\sigma}{}\ansubst{\vv{u_2}/x}{B_1}{\ansubst{\vv{v_2}/y}{B_2}}\eval\vv{w_2}\\
\end{array}
\]

And, $\scal{\vv{w_1}}{\vv{w_2}} = \scal{\vv{u_1}}{\vv{u_2}}$.
\end{lemma}

\begin{proof}
    From the validity of the judgement of the form $\TYP{\Delta, x_A:\sharp A}{\vv{s}}{C}$, a substitution $\sigma\in\sem{\Delta}$, and value distributions $\vv{w_1},\vv{w_2}\in\sem{C}$ such that $\vv{s}\ansubst{\sigma}{}\ansubst{\vv{u_1}/x}{A}\eval\vv{w_1}$ and $\vv{s}\ansubst{\sigma}{}\ansubst{\vv{u_2}/x}{A}\eval\vv{w_2}$. In particular, we have that $\|\vv{w_1}\| = \|\vv{w_2}\|=1$. Applying \Cref{lem:VecRewrite}~four times, we know there are vectors $\vv{u_{01}},\vv{u_{02}},\vv{u_{03}},\vv{u_{04}}\in\sem{\sharp A}$ and scalars $\lambda_1,\lambda_2,\lambda_3,\lambda_4$ such that:
    
    \begin{align*}
        \vv{u_1} + \vv{u_2} = \lambda_1 \vv{u_{01}} & \vv{u_1} + i \vv{u_2} = \lambda_3 \vv{u_{03}} \\
        \vv{u_1} + (-1) \vv{u_2} = \lambda_2 \vv{u_{02}} & \vv{u_1} + (-i) \vv{u_2} = \lambda_4 \vv{u_{04}} \\
    \end{align*}

    From the validity of the judgement  $\TYP{\Delta, x_A:\sharp A}{\vv{s}}{C}$, we also know that there are value distributions $\vv{w_{01}},\vv{w_{02}},\vv{w_{03}},\vv{w_{04}}\in\sem{C}$ such that $\vv{s}\ansubst{\sigma}{}\ansubst{\vv{u_{0j}}}{}\eval\vv{w_{oj}}$ for all $f\in\{1\dotsb 4\}$. Combining the linearity of evaluation on the basis $A$ with the uniqueness of normal forms we deduce from what precedes that:

    \begin{align*}
        \vv{w_1} + \vv{w_2} = \lambda_1 \vv{w_{01}} & \vv{w_1} + i \vv{w_2} = \lambda_3 \vv{w_{03}} \\
        \vv{w_1} + (-1) \vv{w_2} = \lambda_2 \vv{w_{02}} & \vv{w_1} + (-i) \vv{w_2} = \lambda_4 \vv{w_{04}} \\
    \end{align*}

    Using the polarization identity (\Cref{prop:Polarization}), we conclude that:

    \begin{align*}
        &\scal{\vv{w_1}}{\vv{w_2}}\\
        &= \frac{1}{4}(\|\vv{w_1}+\vv{w_2}\| - \|\vv{w_1} + (-1)\vv{w_2}\| - i \|\vv{v_1} + i \vv{v_2}\| + i \|\vv{v_1} + (-i) \vv{v_2}\|)\\
        &= \frac{1}{4}((\lambda_1)^2\|\vv{w_{01}}\| - (\lambda_2)^2\|\vv{w_{02}}\| - i (\lambda_)^2 \|\vv{w_{03}}\| + i (\lambda_)^2\|\vv{w_{04}}\|)\\
        &= \frac{1}{4}((\lambda_1)^2\|\vv{u_{01}}\| - (\lambda_2)^2\|\vv{u_{02}}\| - i (\lambda_)^2 \|\vv{u_{03}}\| + i (\lambda_)^2\|\vv{u_{04}}\|)\\
        &= \frac{1}{4}(\|\vv{u_1}+\vv{u_2}\| - \|\vv{u_1} + (-1)\vv{u_2}\| - i \|\vv{u_1} + i \vv{u_2}\| + i \|\vv{u_1} + (-i) \vv{u_2}\|)\\
        &=\scal{u_1}{u_2}
    \end{align*}

\end{proof}

\begin{lemma}\label{lem:OrthogonalSubstitution} %A8
Given a valid typing judgement of the form $\TYP{\Delta, x_{B_1}:\sharp A_1, y_{B_2}: \sharp A_2}{\vv{s}}{C}$, a substitution $\sigma\in\sem{\Delta}$ and value distributions $\vv{u_1},\vv{u_2}\in\sem{\sharp A}$, there are value distributions $\vv{w_1},\vv{w_2}\in\sem{C}$ such that:
\[
\begin{array}{c}
    \vv{s}\ansubst{\sigma}{}\ansubst{\vv{u_1}/x}{B_1}{\ansubst{\vv{v_1}/y}{B_2}}\eval\vv{w_1}\\
    \vv{s}\ansubst{\sigma}{}\ansubst{\vv{u_2}/x}{B_1}{\ansubst{\vv{v_2}/y}{B_2}}\eval\vv{w_2}\\
\end{array}
\]
And, $\scal{\vv{w_1}}{\vv{w_2}} = 0$.
\end{lemma}

\begin{proof}
    From \Cref{lem:VecRewrite} we know that there are $\vv{u_0}\in\sem{\sharp A}, \vv{v_0}\in\sem{\sharp B}$ and $\lambda,\mu\in\C$ such that:
    \[
    \vv{u_2} + (-1) \vv{u_1} = \lambda\vv{u_0}\quad\text{and}\quad\vv{v_2} + (-1) \vv{v_1} = \mu \vv{v_0}
    \]
    For all $j,k\in\{0,1,2\}$, we have $\vv{s}\ansubst{\sigma}{}\ansubst{\vv{u_j}/x}{B_1}\ansubst{\vv{v_k}/y}{B_2}\eval\vv{w_{jk}}$. In particular, we can take $\vv{w_1}=\vv{w_{11}}$ and $\vv{w_2}=\vv{w_{22}}$. Now we observe that:
    \begin{enumerate}
        \item\label{A8:it1} $\vv{u_1}+\lambda\vv{u_0}= \vv{u_1} + \vv{u_2} + (-1) \vv{u_1}= \vv{u_2} + 0\vv{u_1}$, so that from linearity of substitution, linearity of evaluation and uniqueness of normal forms, we get:
        \[
        \begin{array}{c c}
            \begin{array}{c}
                \vv{w_{1k}} + \lambda\vv{w_{0k}} = \vv{w_{2k}} + 0 \vv{w_{1k}}\\
                \vv{w_{2k}} + (-\lambda)\vv{w_{0k}} = \vv{w_{1k}} + 0 \vv{w_{2k}}
            \end{array}&
            (\text{for all }k\in\{0,1,2\})
        \end{array}
        \]
        
        \item\label{A8:it2} $\vv{v_1}+\mu\vv{v_0}= \vv{v_1} + \vv{v_2} + (-1) \vv{v_1}= \vv{v_2} + 0\vv{v_1}$, so that from linearity of substitution, linearity of evaluation and uniqueness of normal forms, we get:
        \[
        \begin{array}{c c}
            \begin{array}{c}
                \vv{w_{j1}} + \mu\vv{w_{j0}} = \vv{w_{j2}} + 0 \vv{w_{j1}}\\
                \vv{w_{j2}} + (-\mu)\vv{w_{j0}} = \vv{w_{j1}} + 0 \vv{w_{j2}}
            \end{array}&
            (\text{for all }j\in\{0,1,2\})
        \end{array}
        \]
        
        \item\label{A8:it3} $\scal{\vv{u_1}}{\vv{u_2}}=0$, so that from \Cref{lem:InnerProdSingleVar}~we get $\scal{\vv{w_{1k}}}{\vv{w_{2k}}}=0$ (for all $k\in\{0,1,2\}$).
        
        \item\label{A8:it4} $\scal{\vv{v_1}}{\vv{v_2}}=0$, so that from \Cref{lem:InnerProdSingleVar}~we get $\scal{\vv{w_{j1}}}{\vv{w_{j2}}}=0$ (for all $j\in\{0,1,2\}$).
    \end{enumerate}

    From the above, we get:
    \begin{align*}
        \scal{\vv{w_1}}{\vv{w_2}} &= \scal{\vv{w_{11}}}{\vv{w_{22}}} = \scal{\vv{w_{11}}}{\vv{w_{22}}+0\vv{w_{12}}} & \\
        &=\scal{\vv{w_{11}}}{\vv{w_{12}}+ \lambda\vv{w_{02}}} & (\text{from \Cref{A8:it1}, } k=2)\\
        &=\scal{\vv{w_{11}}}{\vv{w_{12}}} + \lambda \scal{\vv{w_{11}}}{\vv{w_{02}}} &\\
        &= 0 + \lambda \scal{\vv{w_{11}}}{\vv{w_{02}}} & (\text{from \Cref{A8:it4}, } j=1)\\
        &= \lambda \scal{\vv{w_{11}} + 0\vv{w_{21}}}{\vv{w_{02}}} & \\
        &= \lambda \scal{\vv{w_{21}} + (-\lambda)\vv{w_{01}}}{\vv{w_{02}}} & (\text{from \Cref{A8:it1}, } k=1)\\
        &= \lambda \scal{\vv{w_{21}}}{\vv{w_{02}}} - |\lambda|^2 \scal{\vv{w_{01}}}{\vv{w_{02}}} & \\
        &= \lambda \scal{\vv{w_{21}}}{\vv{w_{02}}} - 0 & (\text{from \Cref{A8:it4}, } j=0)\\
        &=\scal{\vv{w_{21}}}{\vv{w_{22}}- \vv{w_{12}}} & \\
        &=\scal{\vv{w_{21}}}{\vv{22}} - \scal{\vv{w_{21}}}{\vv{w_12}} & \\
        &= 0 - \scal{\vv{w_{21}}}{\vv{w_{12}}} & (\text{from \Cref{A8:it4}, } j=2)\\
    \end{align*}
    Hence $\scal{\vv{w_1}}{\vv{w_2}} = \scal{\vv{w_{11}}}{\vv{w_{22}}} = - \scal{\vv{w_{21}}}{\vv{w_{12}}}$. Exchanging the indices in the previous reasoning, we also get 
    \[
    \scal{\vv{w_1}}{\vv{w_2}}=-\scal{\vv{w_{21}}}{\vv{w_{12}}}=-\scal{\vv{w_{12}}}{\vv{w_{21}}}
    \]
    So that we have:
    \[
        \scal{\vv{w_1}}{\vv{w_2}}=-\scal{\vv{w_{21}}}{\vv{w_{12}}}=-\overline{\scal{\vv{w_{21}}}{\vv{w_{12}}}}\in\R
    \]
    If we now replace $\vv{u_2}\in\sem{\sharp A}$ with $i\vv{u_2}\in\sem{\sharp A}$, the very same technique allows us to prove that $i\scal{\vv{w_1}}{\vv{w_2}}=\scal{\vv{w_1}}{i \vv{w_2}}\in\R$. Therefore, $\scal{\vv{w_1}}{\vv{w_2}}=0$.
\end{proof}

\begin{lemma}\label{lem:UnitPreserTens} %A9
Given a valid typing judgement of the form $\TYP{\Delta,x_{B_1}:\sharp A_1, y_{B_2}:\sharp A_2}{\vv{s}}{C}$, a substitution $\sigma\in\sem{\Delta}$, and value distributions $\vv{u_1},\vv{u_2}\in\sem{\sharp A}$ and $\vv{v_1},\vv{v_2}\in\sem{\sharp B}$, there are value distributions $\vv{w_1},\vv{w_2}\in\sem{C}$ such that:
\[
\begin{array}{c}
    \vv{s}\ansubst{\sigma}{}\ansubst{\vv{u_1}/x}{B_1}{\ansubst{\vv{v_1}/y}{B_2}}\eval\vv{w_1}\\
    \vv{s}\ansubst{\sigma}{}\ansubst{\vv{u_2}/x}{B_1}{\ansubst{\vv{v_2}/y}{B_2}}\eval\vv{w_2}\\
\end{array}
\]

And, $\scal{\vv{w_1}}{\vv{w_2}} = \scal{\vv{u_1}}{\vv{u_2}} \scal{\vv{v_1}}{\vv{v_2}}$.

\begin{proof}
    Let $\alpha=\scal{\vv{u_1}}{\vv{u_2}}$ and $\beta=\scal{\vv{v_1}}{\vv{v_2}}$. We observe that:
    \[
    \scal{\vv{u_1}}{\vv{u_2}+(-\alpha)\vv{u_1}} = \scal{\vv{u_1}}{\vv{u_2}} - \alpha \scal{\vv{u_1}}{\vv{u_1}} = \alpha - \alpha = 0
    \]
    And similarly that, $\scal{\vv{v_1}}{\vv{v_2}+ (-\beta) \vv{v_1}} = 0$. From \Cref{lem:VecRewrite}, we know that there are $\vv{u_0}\in\sem{\sharp A}$, $\vv{v_0}\in\sem{\sharp B}$ and $\lambda,\mu\in\C$ such that:
    \begin{align*}
        \vv{u_2} +(-\alpha)\vv{u_1} = \lambda\vv{u_0}& \text{ and } & \vv{v_2} + (-\beta)\vv{v_1} = \mu\vv{v_0} 
    \end{align*}
    For all $j,k\in\{0,1,2\}$, we have$\ansubst{\sigma}{}\ansubst{\vv{u_j}/x}{B_1}\ansubst{\vv{v_k}/y}{B_2}\in\sem{\Delta,x_{B_1}:\sharp A_1, y_{B_2}:\sharp A_2}$, hence there is $\vv{w_{jk}}\in\sem{C}$ such that:
    \[
    \vv{s}\ansubst{\sigma}{}\ansubst{u_j/x}{B_1}\ansubst{\vv{v_k}/y}{B_2}\eval\vv{w_{jk}}
    \]
    In particular, we can take $\vv{w_1}=\vv{w_{11}}$ and $\vv{w_2}=\vv{w_{22}}$. Now we observe that:
    \begin{enumerate}
        \item\label{A9:it1} $\lambda \vv{u_0} + \alpha\vv{u_1}=\vv{u_2} + (-\alpha) \vv{u_1} + \alpha \vv{u_1} = \vv{u_2} + 0 \vv{u_1}$, so that from the linearity of the substitution, linearity of evaluation and uniqueness of normal forms, we get:
        \[
        \lambda\vv{w_{0k}} + \alpha \vv{w_{1k}} = \vv{w_{2k}} + 0 \vv{w_{1k}} \qquad(\text{for all }k\in\{0,1,2\})
        \]
        
        \item\label{A9:it2} $\mu\vv{v_0} + \beta\vv{v_1}=\vv{v_2} + (-\beta) \vv{v_1} + \beta \vv{v_1} = \vv{v_2} + 0 \vv{v_1}$, so that from the linearity of the substitution, linearity of evaluation and uniqueness of normal forms, we get:
        \[
        \mu\vv{w_{j0}} + \beta \vv{w_{j1}} = \vv{w_{j2}} + 0 \vv{w_{j1}} \qquad(\text{for all }j\in\{0,1,2\})
        \]
        
        \item\label{A9:it3} $\scal{\vv{u_1}}{\lambda\vv{u_0}}=\scal{\vv{u_1}}{\vv{u_2}+(- \alpha)\vv{u_1}}=0$, so that from \Cref{lem:InnerProdSingleVar} we get:
        \[
        \scal{\vv{w_{1k}}}{\lambda\vv{w_{0k}}}= 0 \qquad(\text{for all }k\in\{0,1,2\})
        \]
        
        \item\label{A9:it4} $\scal{\vv{v_1}}{\mu\vv{v_0}}=\scal{\vv{v_1}}{\vv{v_2} + (-\beta)}\vv{v_1}=0$, so that from \Cref{lem:InnerProdSingleVar} we get:
        \[
        \scal{\vv{w_{j1}}}{\mu\vv{w_{j0}}}=0
        \]
                
        \item\label{A9:it5} $\scal{\vv{u_1}}{\lambda\vv{u_0}}=\scal{\vv{v_1}}{\mu\vv{v_0}}=0$ so that from \Cref{lem:OrthogonalSubstitution} we get:
        \[
        \scal{\vv{w_{11}}}{\lambda\mu\vv{w_{00}}}=0
        \]
        (Again the equality $\scal{\vv{w_{11}}}{\lambda\mu\vv{w_{00}}}$ is trivial when $\lambda=0$ or $\mu=0$. When $\lambda ,\mu\neq 0$ we deduce from the above that $\scal{\vv{u_1}}{\vv{u_0}}=\scal{\vv{v_1}}{\vv{v_0}}=0$, from which we get $\scal{\vv{w_{11}}}{\vv{w_{00}}}=0$ by \Cref{lem:OrthogonalSubstitution})
    \end{enumerate}

    From above, we get:
    \begin{align*}
        \vv{w_{22}} + 0\vv{w_{12}} + &0\vv{w_{01}} + 0\vv{w_{11}} \\
        &= \lambda\vv{w_{02}} + \alpha\vv{w_{12}} + 0\vv{w_{01}} + 0\vv{w_{11}} & (\text{from~\Cref{A9:it1}}, k =1)\\
        &= \lambda(\vv{w_{02}}+0\vv{w_{01}}) + \alpha(\vv{w_{12}}+0\vv{w_{11}})&\\
        &= \lambda(\mu\vv{w_{00}} + \beta\vv{w_{01}}) + \alpha(\mu\vv{w_{01}}+\beta\vv{w_{11}}) & (\text{from~\Cref{A9:it2}}, j=0,1)\\
        &= \lambda\mu\vv{w_{00}} + \lambda\beta\vv{w_{01}} + \alpha\mu\vv{w_{10} + \alpha\beta\vv{w_{11}}}
    \end{align*}
    Therefore:
    \begin{align*}
        &\scal{\vv{w_1}}{\vv{w_2}} \\
        &= \scal{\vv{w_{11}}}{\vv{w_{22}} + 0 \vv{w_{12}} + 0 \vv{w_{01}} + 0 \vv{w_{11}}}\\
        &= \scal{\vv{w_{11}}}{\lambda\mu\vv{w_{00}} + \lambda\beta\vv{w_{01}} + \alpha\mu\vv{w_{10} + \alpha\beta\vv{w_{11}}}}\\
        &=\scal{\vv{w_{11}}}{\lambda\mu\vv{w_{00}}} + \scal{\vv{w_{11}}}{\lambda\beta\vv{w_{01}}} + \scal{\vv{w_{11}}}{\alpha\mu\vv{w_{10}}} + \scal{\vv{w_{11}}}{\alpha\beta\vv{w_{11}}}\\
        &=\lambda\mu\scal{\vv{w_{11}}}{\vv{w_{00}}} + \lambda\beta\scal{\vv{w_{11}}}{\vv{w_{01}}} + \alpha\mu\scal{\vv{w_{11}}}{\vv{w_{10}}} + \alpha\beta\scal{\vv{w_{11}}}{\vv{w_{11}}}\\
        &= 0 + 0 + 0 + \alpha\beta = \scal{\vv{u_1}}{\vv{u_2}}\scal{\vv{v_1}}{\vv{v_2}}
    \end{align*}
    From~\Cref{A9:it5,A9:it3,A9:it4} with $j=1$ and concluding with the definition of $\alpha$ and $\beta$.
\end{proof}
\end{lemma}



\end{document}
