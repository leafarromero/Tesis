\section{Core language}\label{sec:calculus}
\subsection{Syntax and congruence}
This section presents the calculus on which our realisability model will be
built. It is a $\lambda$-calculus extended with linear combinations of terms, in the line of~\cite{ArrighiDowekLMCS17}.

The syntax of the calculus is described in
\Cref{tab:Syntax}. The calculus is divided into four
distinct syntactic categories: \emph{basic values} ($\Val$), \emph{basic terms}
($\Lambda$), \emph{value distributions} ($\ValD$), and \emph{term
distributions} ($\vv\Lambda$). Values are composed of variables, decorated
lambda abstractions, and two basis values representing orthogonal vectors,
$\ket 0$ and $\ket 1$. A pair of values is also considered a value.  Terms
include values, applications, pair constructors and destructors, and pattern
matching for orthogonal vectors, represented by the $\mathsf{case}$ operator.
Both term and value distributions are built as $\C$-linear combinations of
terms and values, respectively. 
We use $v,u,w$ to denote values and $t,s,r$ for terms, writing $\vv{\cdot}$ when
they are distributions.

The subsets $B$, $B_1$, and $B_2$ appearing in the abstractions and pair
destructors denote the bases of the vector spaces in which the terms are
expressed; their precise nature is made explicit below.
Before formally defining the notion of bases, we first establish the
algebraic structure underlying the space of value distributions.
This is achieved by introducing the congruence relation defined in
\Cref{tab:Congruence}.
The congruence captures the intended behaviour of addition and scalar
multiplication, allowing us to treat linear combinations of terms and values
as genuine algebraic entities rather than mere syntactic constructions.
In particular, it enforces the commutativity and associativity of addition and
the distributivity of scalar multiplication, thereby justifying summation
notation~$\vv\sum$.

\begin{table}[t]
  \begin{align*}
    v &::= x \mid \Lam{x}B{\vv{t}} \mid (v, v) \mid \ket{0} \mid \ket{1} &
    (\Val)\\
    t &::= v \mid tt \mid (t,t) \mid
    \LetP{x}{B_1}{y}{B_2}{\vv{t}}{\vv{t}}\mid
    \gencase{\vv{t}}{\vv{v}}{\vv{v}}{\vv{t}}{\vv{t}} &
    (\Lambda) \\
    \vv{v} &::= v \mid \vv{v}+\vv{v} \mid \alpha \vv{v} \mid \vv 0
    \qquad\hfill(\alpha\in\C) & (\ValD) \\
    \vv{t} &::= t \mid \vv{t}+\vv{t} \mid \alpha \vv{t} \mid \vv 0
    \qquad\hfill(\alpha\in\C) & (\vv \Lambda)
  \end{align*}
  \caption{Syntax of the calculus, where $B, B_1, B_2 \subseteq \ValD$.}
  \label{tab:Syntax}
\end{table}
\begin{table}[t]
  \begin{align*}
    0\vv t &\equiv \vv 0 & \vv t+\vv 0 &\equiv \vv t \\
    1\vv{t} &\equiv \vv{t} &
    \alpha(\beta\vv{t}) &\equiv (\alpha\beta)\vv{t} \\
    \vv{t_1}+\vv{t_2} &\equiv \vv{t_2}+\vv{t_1} &
    (\vv{t_1}+\vv{t_2})+\vv{t_3} &\equiv \vv{t_1}+(\vv{t_2}+\vv{t_3}) \\
    (\alpha+\beta)\vv{t} &\equiv \alpha\vv{t}+\beta\vv{t} &
    \alpha(\vv{t_1}+\vv{t_2}) &\equiv \alpha\vv{t_1}+\alpha\vv{t_2} \\
    \vv{t}(\alpha\vv{s}) &\equiv \alpha(\vv{t}\vv{s}) &
    (\alpha\vv{t})\vv{s} &\equiv \alpha(\vv{t}\vv{s}) \\
    (\vv{t}+\vv{s})\vv{r} &\equiv \vv{t}\vv{r}+\vv{s}\vv{r} &
    \vv{t}(\vv{s}+\vv{r}) &\equiv \vv{t}\vv{s}+\vv{t}\vv{r} &&
  \end{align*}
  \vspace{-2\baselineskip}
  \begin{align*}
    &\LetP{x_1}{X}{x_2}{Y}{(\alpha\vv{t})}{\vv{s}}
    \equiv \alpha(\LetP{x_1}{X}{x_2}{Y}{\vv{t}}{\vv{s}}) \\
    &\LetP{x_1}{X}{x_2}{Y}{\vv{t}+\vv{s}}{\vv{r}}
    \equiv
      (\LetP{x_1}{X}{x_2}{Y}{\vv{t}}{\vv{r}})
      +(\LetP{x_1}{X}{x_2}{Y}{\vv{s}}{\vv{r}}) 
      \\
    &\gencase{\alpha \vv{t}}{\vv{v_1}}{\vv{v_n}}{\vv{s_1}}{\vv{s_n}}
    \equiv \alpha(\gencase{\vv{t}}{\vv{v_1}}{\vv{v_n}}{\vv{s_1}}{\vv{s_n}}) \\
    &\gencase{(\vv{t}+\vv{s})}{\vv{v}}{\vv{w}}{\vv{r_1}}{\vv{r_2}}
    \equiv\begin{aligned}[t]
      &\gencase{\vv{t}}{\vv{v}}{\vv{w}}{\vv{r_1}}{\vv{r_2}}\\
      &+\gencase{\vv{s}}{\vv{v}}{\vv{w}}{\vv{r_1}}{\vv{r_2}}
    \end{aligned}
  \end{align*}
  \caption{Term congruence}
  \label{tab:Congruence}
\end{table}

The rules in \Cref{tab:Congruence} ensure that the
set of value distributions satisfies the axioms of a vector space.  The notion
of basis in this calculus builds on this algebraic foundation. Once the vector
structure is established, we can define which subsets $B\subseteq \ValD$
qualify as \emph{bases}, thereby justifying the decorations appearing in the
syntax of \Cref{tab:Syntax}.

We will also consider the following notation for linear combinations of
pairs. We stress that this notation for pairs does not appear in the syntax,
but is rather useful to describe specific states.
\[
  \Pair{\alpha  t+\vv{t_1}}{\vv{t_2}} 
  := \alpha\Pair{t}{\vv{t_2}} + \Pair{\vv{t_1}}{\vv{t_2}}
  \qquad\qquad
  \Pair{r}{\alpha  t+\vv{t_1}} 
  := \alpha\Pair{r}{t} + \Pair{r}{\vv{t_1}}
\]


Before proceeding further, let us briefly illustrate the intuition behind the
congruence in \Cref{tab:Congruence}.  
The key idea is that arguments are decomposed over the bases associated with
their corresponding abstractions.  
As in linear algebra, a vector can be rewritten as a linear combination of
basis elements; for instance,
\(
  (1,0)
  = \tfrac{1}{\sqrt{2}}\!\left(\tfrac{(1,1)}{\sqrt{2}}
  + \tfrac{(1,-1)}{\sqrt{2}}\right)
\)
expresses $(1,0)$ in the basis
$\{\tfrac{(1,1)}{\sqrt{2}}, \tfrac{(1,-1)}{\sqrt{2}}\}$.
By identifying $(1,0)$ with $\ket{0}$ and $(0,1)$ with $\ket{1}$, we see that
the calculus allows every vector (or value distribution) to be expressed as a
superposition of elements of the basis attached to each abstraction.
The congruence ensures that these linear combinations behave algebraically as
in a complex vector space, supporting the standard operations of addition,
scalar multiplication, and the zero vector.

To properly characterise the sets that decorate the lambda abstractions, we
must first specify the kind of values they contain.
\begin{definition}[Qubits]\label{def:Qubit}
  A \emph{one-dimensional qubit} is a value distribution of the form
  $\alpha\ket{0} + \beta\ket{1}$, where $|\alpha|^2 + |\beta|^2 = 1$. An
  \emph{$n$-dimensional qubit} is a value distribution of the form
  $\alpha\Pair{\ket{0}}{\vv{w_1}} + \beta\Pair{\ket{1}}{\vv{w_2}}$, where
  $\vv{w_1}$ and $\vv{w_2}$ are $(n-1)$-dimensional qubits, and $\alpha$ and
  $\beta$ satisfy the same normalisation condition.
\end{definition}
We use the usual Dirac shorthand $\ket{xy}$ for $(\ket{x},\ket{y})$, and
extend it to longer tuples by associating to the right.

From now on, we call the value distributions, i.e. the elements of $\ValD$,
\emph{vectors}. The vector space $\ValD$ is equipped with an inner
product defined by,  
\(
  \scal{\vv{v}}{\vv{w}} := \sum_{i=1}^n\sum_{j=1}^m
  \overline{\alpha_i}\,\beta_j\,\delta_{v_i,w_j},
\)
and an $\ell_2$-norm 
\(
  \|\vv{v}\| := \sqrt{\scal{\vv{v}}{\vv{v}}}
  = \sqrt{\sum_{i=1}^n|\alpha_i|^2}
\),
where $\vv{v}=\sum_{i=1}^n\alpha_i v_i$ and
$\vv{w}=\sum_{j=1}^m\beta_j w_j$, and $\delta_{v_i,w_j}$ is the Kronecker
delta, equal to $1$ if $v_i=w_j$ and $0$ otherwise.

With this notion of inner product, we can complete the description of the
calculus syntax. As expected, two values are \emph{orthogonal} when their inner
product is equal to zero. We can now formally define the sets that
decorate abstractions.
\begin{definition}[Basis]\label{def:NthDimensionalBasis}
  A set of value distributions $B$ is an \emph{$n$-dimensional orthonormal
  basis} if it satisfies:
  \begin{enumerate}
    \item Each element of $B$ is an $n$-dimensional qubit \emph{(cf.~\Cref{def:Qubit})}.
    \item Distinct elements of $B$ are pairwise orthogonal.
  \end{enumerate}
\end{definition}

From now on, the syntax introduced in \Cref{tab:Syntax}
is restricted to sets $B$ forming $n$-dimensional
orthonormal bases.


Unlike standard orthonormal bases, we require that their elements be qubits
(rather than variables or abstractions).  
These sets indicate the basis in which a term is expressed: qubits in the
decorating basis are treated call-by-value, while others are decomposed as
$\C$-linear combinations of basis elements, with the function applied linearly
to each component.  If a term cannot be expressed in the decorating basis,
evaluation becomes stuck.

As in classical linear algebra, no non-trivial linear combination of basis
elements yields the null vector; otherwise, some basis vector would violate
pairwise orthogonality. Consequently, each decomposition over a basis is
unique.

\begin{theorem}[Unique decomposition]\label{thm:UniqueDecomposition}
  If $B$ is an $n$-dimensional basis, then every $n$-dimensional qubit has a
  unique decomposition over $B$.
  \qed
\end{theorem}
\begin{proof}
  Let $\vv{b_i}$, the basis vectors of $B$. And $\sum_i^n\alpha_i \vv{b_i}$, $\sum_{i=1}^n \beta_i \vv{b_i}$ two decompositions of $\vv{v}$ onto $B$. Then we have:
  \[\vv{v} - \vv{v} = 0 \; \vv{v} = \sum_{i=1}^{n} (\alpha_i - \beta_i) \vv{b_i}\]
  Since the basis is linearly independent, $\alpha_i = \beta_i$.
\end{proof}


\begin{corollary}[Preservation under congruence]\label{cor:EquivalentDecomposition}
  If $\vv{v} \equiv \vv{w}$, then they share the same decomposition over any
  basis $B$.
  \qed
\end{corollary}
\begin{proof}
  Since $\vv{v} - \vv{w} \equiv \vv{v} - \vv{v} \equiv \vv{w} - \vv{w}$, we can use the same reasoning as proposition \ref{prop:UniqueDecomposition} to conclude that both have the same decomposition.
\end{proof}

We denote the computational basis by $\B=\{\ket{0},\ket{1}\}$ and the diagonal
basis by $\XB=\{\ket{+},\ket{-}\}$, where
$\ket{\pm}=\tfrac{1}{\sqrt{2}}(\ket{0}\pm\ket{1})$.  

\subsection{Basis-dependent substitutions}
As usual, the expression $\vv t[\vv v/x]$ denotes the
usual capture-avoiding substitution of $\vv v$ for $x$ in $\vv t$.
However, beta-reduction depends on the basis chosen for the abstraction, so we must
define a substitution that takes this mechanism into account. Intuitively, this
operation substitutes variables with vectors expressed in the chosen basis; the
accompanying coefficients are those of the value distribution being
substituted.

Alongside this substitution, we expand the set of orthogonal basis with a 
special symbol, denoted $\AbsBasis$. This symbol changes the modality of the lambda
abstraction, allowing it to take other abstractions as arguments. This is the only
instance of higher-order functions in the calculus. The $\AbsBasis$, is a purely
syntactical device, intuitively it can be thought as the canonical basis.


\begin{definition}[Basis-dependent substitution]
  Let $\vv t$ be a term distribution, $\vv v$ a value distribution, $x$ a
  variable, and $B$ an orthonormal basis. We define the substitution
  $\vv t\ansubst{\vv v/x}{B}$ as follows:
  \[
    \vv t\ansubst{\vv v/x}{B} \;=\;
    \begin{cases}
      \ds\sum_{i\in I}\alpha_i\,\vv t\,[\vv{b_i}/x] &
        \text{if } B=\{\vv{b_i}\}_{i\in I}\ \text{and}\
        \vv v \equiv \ds\sum_{i\in I}\alpha_i\,\vv{b_i},\\[6pt]
      \ds\sum_{i\in I}\alpha_i\,\vv t\,[v_i/x] &
        \text{if } B=\AbsBasis\ \text{and}\
        \vv v = \ds\sum_{i\in I}\alpha_i\,v_i,\\[2pt]
      \text{undefined} & \text{otherwise.}
    \end{cases}
  \]
\end{definition}

The two cases in the definition capture distinct substitution modes.  
In the first, substitution proceeds linearly using the decomposition of
$\vv v$ over the explicit basis $B$.  
In the second, when $B=\AbsBasis$, substitution proceeds linearly over the basic
values that form $\vv v$.  
This case recovers the substitution mechanism of 
non base-sensitive calculi---as first defined in
\cite{ArrighiDowekLMCS17}---but generalises it by introducing
basis-dependent behaviour.  
This special case is also the only one applicable to
$\lambda$-abstractions, since abstractions do not belong to orthonormal bases.

The definition also extends to pairs of values. If
$\vv v=\sum_{i\in I}\alpha_i\,\Pair{\vv{v_i}}{\vv{w_i}}$,
with $\vv{v_i}\in\Span(B_1)$ and $\vv{w_i}\in\Span(B_2)$,
then
\[
  \vv t\ansubst{\vv v/x\otimes y}{B_1\otimes B_2}
    \;=\; \sum_{i\in I}\alpha_i\,
    \bigl(\vv t\ansubst{\vv{v_i}/x}{B_1}\ansubst{\vv{w_i}/y}{B_2}\bigr),
\]
where $B_1$ and $B_2$ are (orthonormal) bases---or $\AbsBasis$---associated
with $x$ and $y$, respectively; the symbol $\otimes$ in $B_1\otimes B_2$ is
purely notational.

\begin{example}
  Let
  $\vv v = \alpha\ket{01}
           + \beta\ket{10}$.
  Then 
  \[
    (y,x)\ansubst{\vv v/x\otimes y}{\B\otimes\B}
    = \alpha\,(y,x)[\ket{0}/x][\ket{1}/y]
    + \beta\,(y,x)[\ket{1}/x][\ket{0}/y] 
    = 
    \alpha\ket{10}
    + \beta\ket{01}
  \]
\end{example}

With this substitution in place, we can establish certain needed properties.
First, basis-dependent substitution distributes over linear combinations.

\begin{lemma}[Distributivity over linear combinations]\label{lem:distributiveSubstitution}
  For term distributions $\vv{t_i}$, a value distribution $\vv{v}$, a
  variable $x$, coefficients $\alpha_i\in\C$, and a basis $B$ such that
  $\ansubst{\vv v/x}{B}$ is defined:
  \(
    \Bigl(\sum_i \alpha_i\vv{t_i}\Bigr)\ansubst{\vv v/x}{B}
    \equiv
    \sum_i \alpha_i\vv{t_i} \ansubst{\vv v/x}{B}
  \).
  \qed
\end{lemma}

\begin{proof}
  Let $B\neq\AbsBasis$ and $\vv{v}\equiv\sum\limits_{j=0}^n \beta_j \vv{b_j}$ with each $\vv{b_j}\in B$
  \begin{align*}
    (\sum_i \alpha_i\vv t)\ansubst{\vv v/x}{B} &= \sum_{j=1}^m \beta_j(\sum_{i=1}^{n} \alpha_i t_i)[\vv b_j/x]\\
    &\equiv \sum_{i=1}^{n} \alpha_i (\sum_{j=1}^m \beta_j t_i [\vv b_j/x])\\
    &= \sum_{i=1}^{n} \alpha_i \vv{t_i}\ansubst{\vv v/x}{B}
  \end{align*}
  The case where $B=\AbsBasis$ is similar.
\end{proof}

The next result states that substitution behaves consistently within each
equivalence class induced by the congruence $\equiv$.

\begin{lemma}[Compatibility with congruence]\label{lem:EquivSubstitutions}
  For value distributions $\vv{v},\vv{w}$, a term distribution $\vv{t}$, and
  an orthonormal basis $B$ such that both
  $\ansubst{\vv{v}/x}{B}$ and $\ansubst{\vv{w}/x}{B}$ are defined:
  if $\vv{v}\equiv\vv{w}$, then
  $\vv{t}\ansubst{\vv{v}/x}{B}
  =\vv{t}\ansubst{\vv{w}/x}{B}$.
  \qed
\end{lemma}

\begin{proof}
  Since $\vv{v}\equiv\vv{w}$, by Corollary \ref{cor:EquivalentDecomposition}, we have that both $\vv{v}$ and $\vv{w}$ can be written as:
  \[
  \vv{v} \equiv \vv{w} \equiv \sum_{i=1}^{n} \alpha_i \vv{b_i}\qquad\text{Where }\vv{b_i}\in B
  \]
  Then:
  \[
  \vv{t}\ansubst{\vv{v}/x}{B} = \sum_{i=1}^{n} \alpha_i \vv{t}\ [\vv{b_i}/x] = \vv{t}\ansubst{\vv{w}/x}{B}
  \]
\end{proof}

We remark that the result in the previous lemma uses $=$ instead of $\equiv$
since $\vv{t}\ansubst{\vv{v}/x}{B}$ and $\vv{t}\ansubst{\vv{w}/x}{B}$
are both substitution with the exact same outcome. Note that this property
does not extend across different bases; that is, $\vv{t}\ansubst{\vv{v}/x}{A}
\not\equiv\vv{t}\ansubst{\vv{v}/x}{B}$.
For example,
\[
  (\Lam{x}{C}{y})\ansubst{\ket{+}/y}{\XB}
  = \Lam{x}{C}{\ket{+}} 
  \not\equiv
  \tfrac{1}{\sqrt{2}}\big((\Lam{x}{C}{\ket{0}})
  + (\Lam{x}{C}{\ket{1}})\big)
  = (\Lam{x}{C}{y})\ansubst{\ket{+}/y}{\B}.
\]
This difference arises because the relation $\equiv$ does not commute with
lambda abstraction, nor with the case construct. Although the two terms are
operationally equivalent, the calculus distinguishes between the
superposition of results,
$\Lam{x}{B}{\alpha\vv{v_1} + \beta\vv{v_2}}$,
and the superposition of functions,
$\alpha(\Lam{x}{B}{\vv{v_1}}) + \beta(\Lam{x}{B}{\vv{v_2}})$.
This distinction reflects a physical intuition: the former corresponds to a
single experiment producing a superposition of outcomes, while the latter
represents a superposition of distinct experiments.

Finally, we introduce a convenient notation for generalised substitutions over
a term by closed values. A substitution $\sigma$ can be seen as a finite set of
individual substitutions applied consecutively to a term. Formally, for a term
$\vv{t}$, closed value distributions $\vv{v_1},\dots,\vv{v_n}$, variables
$x_1,\dots,x_n$, and bases $B_1,\dots,B_n$:
\[
  \vv{t}\ansubst{\sigma}{}
  := \vv{t}\ansubst{\vv{v_1}/x_1}{B_1}\dotsb\ansubst{\vv{v_n}/x_n}{B_n}.
\]
Since each $\vv{v_i}$ is closed, the order of substitutions is irrelevant. We
regard $\sigma$ as a partial function from variables to pairs of closed value
distributions and bases, and write $\dom{\sigma}$ for its domain. The operation
extends naturally: for a term $\vv{t}$, substitution $\sigma$, a new variable
$x\notin\dom{\sigma}$, value distribution $\vv{v}$, and basis $B$,
\(
  \vv{t}\ansubst{\sigma}{}\ansubst{\vv{v}/x}{B}
  = \vv{t}\ansubst{\sigma'}{}
\),
where $\sigma'$ extends $\sigma$ by mapping $x$ to $(\vv v,B)$. Likewise, two
disjoint substitutions $\sigma_1$ and $\sigma_2$ can be merged:
\(
  \vv{t}\ansubst{\sigma_1}{}\ansubst{\sigma_2}{}
  = \vv{t}\ansubst{\sigma'}{}
\),
where $\dom{\sigma_1}\cap\dom{\sigma_2}=\emptyset$ and $\sigma'$ coincides with
$\sigma_i$ on $\dom{\sigma_i}$ for $i=1,2$.
